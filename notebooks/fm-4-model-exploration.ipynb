{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are facing a regression problem. Since the relationship between features and target is non-linear and interactions between features are to be expected, a decision-tree based approach seems appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my method from the source code\n",
    "%aimport features.build_features\n",
    "%aimport visualization.visualize\n",
    "from features.build_features import read_raw_data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15139392197163504, 0.1360043354727259, 0.1499187014755776, 0.1337637893727601, 0.14944426780692585, 0.15091743943287841, 0.14467944906123012, 0.13596761845723826, 0.1323531749571777, 0.14320722044664486]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from math import sqrt\n",
    "\n",
    "df = read_raw_data(\"../data/processed/eval.csv\")\n",
    "X = df.drop(['SalePrice','Id'], axis=1)\n",
    "y = df['SalePrice'] \n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(gbr, X, y, cv=shuffle_split, scoring='neg_mean_squared_log_error')\n",
    "scores = [sqrt(abs(s)) for s in scores]\n",
    "\n",
    "print(scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting regressor with default parameters already achieves reasonable results in cross validation. Let's see what happens if we combine it with the feature reduction explored in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features retained with SelectKBest - mutual_info_regression :\n",
      "Index(['OverallQual', 'ExterQual', 'BsmtQual', '1stFlrSF', 'GrLivArea',\n",
      "       'FullBath', 'KitchenQual', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea'],\n",
      "      dtype='object')\n",
      "[0.16826150189704298, 0.17361925618148322, 0.17124582598039265, 0.1783035727114947, 0.16417803746239823, 0.17253943610649441, 0.161793649683385, 0.15705002138473306, 0.16386381609246964, 0.16463183385725166]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "df = read_raw_data(\"../data/processed/eval.csv\")\n",
    "y = df['SalePrice']\n",
    "X = df.drop(['SalePrice', 'Id'], axis=1)\n",
    "\n",
    "selector = SelectKBest(f_regression, k=10)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "mask_sk = selector.get_support()\n",
    "print(\"Features retained with SelectKBest - mutual_info_regression :\\n{}\".format(X.columns[mask_sk]))\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(gbr, X_new, y, cv=shuffle_split, scoring='neg_mean_squared_log_error')\n",
    "scores = [sqrt(abs(s)) for s in scores]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of the prediction visibly deteriorates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features retained with Recursive Feature Elimination - Gradient boosting regressor :\n",
      "Index(['LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'BsmtUnfSF',\n",
      "       '1stFlrSF', 'GrLivArea', 'GarageYrBlt', 'GarageArea', 'BsmtFinSF'],\n",
      "      dtype='object')\n",
      "[0.15485111805775933, 0.15954230140236256, 0.15488490788950504, 0.1505861303581483, 0.1460030156791995, 0.13328329002850225, 0.13374513233538196, 0.15487189015202468, 0.12622506787525165, 0.14268790551625196]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "rfegbr = GradientBoostingRegressor()\n",
    "rfe = RFE(estimator=rfegbr, n_features_to_select=10, step=1)\n",
    "X_new = rfe.fit_transform(X, y)\n",
    "mask_rfe = rfe.get_support()\n",
    "print(\"Features retained with Recursive Feature Elimination - Gradient boosting regressor :\\n{}\".format(X.columns[mask_rfe]))\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(gbr, X_new, y, cv=shuffle_split, scoring='neg_mean_squared_log_error')\n",
    "scores = [sqrt(abs(s)) for s in scores]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With RFE the quality deteriorates as well, however less so than with the SelectKBest Feature Selection. It would be worthwile to select the ideal number of features using grid cross validation. The same holds for the parameters of the gradient boosting regressor.\n",
    "\n",
    "A possible improvement for the feature selection might be to select features with cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features retained with Recursive Feature Elimination CV - Gradient boosting regressor :\n",
      "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
      "       'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'BsmtQual', 'BsmtExposure',\n",
      "       'BsmtUnfSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'KitchenQual',\n",
      "       'FireplaceQu', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
      "       'OpenPorchSF', 'ScreenPorch', 'MSZoning_C (all)',\n",
      "       'Neighborhood_Crawfor', 'Neighborhood_StoneBr', 'Condition1_Norm',\n",
      "       'Exterior1st_BrkFace', 'Functional_Typ', 'SaleType_New',\n",
      "       'SaleCondition_Abnorml', 'BsmtFinSF'],\n",
      "      dtype='object')\n",
      "[0.14611250382625218, 0.13399878708922558, 0.13557921763462974, 0.15332844168918816, 0.13635773036791987, 0.13502128010757636, 0.1321793668873622, 0.13906389927745016, 0.14328086127093473, 0.1486450145298405]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "rfegbr = GradientBoostingRegressor()\n",
    "rfecv = RFECV(estimator=rfegbr, step=1)\n",
    "X_new = rfecv.fit_transform(X, y)\n",
    "mask_rfecv = rfecv.get_support()\n",
    "print(\"Features retained with Recursive Feature Elimination CV - Gradient boosting regressor :\\n{}\".format(X.columns[mask_rfecv]))\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(gbr, X_new, y, cv=shuffle_split, scoring='neg_mean_squared_log_error')\n",
    "scores = [sqrt(abs(s)) for s in scores]\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RFECV finishes by selecting 31 features. \n",
    "Let's freeze this number of features and continue setting the parameters of the gradient boosting regressor using a gridsearch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross_validaton score : -0.018\n",
      "Test set score : -0.015\n",
      "Best parameters : {'gbr__max_depth': 4, 'gbr__subsample': 0.75}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "rfegbr = GradientBoostingRegressor()\n",
    "rfe = RFE(estimator=rfegbr, n_features_to_select=31, step=1)\n",
    "\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1)\n",
    "param_grid = {'gbr__max_depth' : [3,4,5],\n",
    "              'gbr__subsample' : [1, 0.75],}\n",
    "pipe = Pipeline([(\"rfe\", rfe), (\"gbr\", gbr)])\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, scoring='neg_mean_squared_log_error')\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross_validaton score : {:.3f}\".format(grid.best_score_))\n",
    "print(\"Test set score : {:.3f}\".format(grid.score(X_test, y_test)))\n",
    "print(\"Best parameters : {}\".format(grid.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross_validaton score : 0.135\n"
     ]
    }
   ],
   "source": [
    "print(\"Best cross_validaton score : {:.3f}\".format(sqrt(abs(grid.best_score_))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth: 200624, predict.: 212339.1626418124, score: 0.05675203565080267\n",
      "truth: 133000, predict.: 145334.05991101748, score: 0.08868518774155554\n",
      "truth: 110000, predict.: 104717.11580466968, score: 0.0492173279183703\n",
      "truth: 192000, predict.: 213697.33622340337, score: 0.10706479637589617\n",
      "truth: 88000, predict.: 94141.73117734843, score: 0.06746386937116355\n",
      "truth: 85000, predict.: 99724.93945941646, score: 0.1597627971206439\n",
      "truth: 282922, predict.: 271499.6781304465, score: 0.04121013872689261\n",
      "truth: 141000, predict.: 138670.64527751564, score: 0.016658108159337104\n",
      "truth: 745000, predict.: 447567.877080425, score: 0.5095551195258459\n",
      "truth: 148800, predict.: 158243.21134784553, score: 0.061529638388201136\n",
      "truth: 208900, predict.: 201292.97178451822, score: 0.037094069758779824\n",
      "truth: 136905, predict.: 142123.88120466113, score: 0.037411557273845375\n",
      "truth: 225000, predict.: 229588.80098188133, score: 0.020189396009167027\n",
      "truth: 123000, predict.: 122153.98707727317, score: 0.006901861065500725\n",
      "truth: 119200, predict.: 120798.12339325981, score: 0.013317884938267355\n",
      "truth: 145000, predict.: 149172.52216383105, score: 0.028369567682425156\n",
      "truth: 190000, predict.: 228593.85357328336, score: 0.18492190299997802\n",
      "truth: 123600, predict.: 128000.99247482108, score: 0.034987194402255284\n",
      "truth: 149350, predict.: 130612.59067714658, score: 0.13405596551502974\n",
      "truth: 155000, predict.: 175312.00754816338, score: 0.1231414223068743\n",
      "truth: 166000, predict.: 128766.40930276088, score: 0.253986064146531\n",
      "truth: 144500, predict.: 143760.54474120183, score: 0.005130440247937074\n",
      "truth: 110000, predict.: 128150.1193634627, score: 0.15272073090271654\n",
      "truth: 174000, predict.: 159886.98183879128, score: 0.0845875897920898\n",
      "truth: 185000, predict.: 188685.21507023668, score: 0.019724167144934412\n",
      "truth: 168000, predict.: 184590.96577804344, score: 0.09417786702600672\n",
      "truth: 177500, predict.: 166200.43816521225, score: 0.06577570709821856\n",
      "truth: 84500, predict.: 77132.27395003656, score: 0.09122861239998237\n",
      "truth: 320000, predict.: 386572.882246314, score: 0.18899888614066462\n",
      "truth: 118500, predict.: 108371.33973836401, score: 0.08934851137888877\n",
      "truth: 110000, predict.: 124316.65237757986, score: 0.12235054607412721\n",
      "truth: 213000, predict.: 198476.21109427046, score: 0.07062257256793103\n",
      "truth: 156000, predict.: 144088.33529942445, score: 0.07942892624423514\n",
      "truth: 250000, predict.: 290522.0462793331, score: 0.15021798843845957\n",
      "truth: 372500, predict.: 304154.02445723437, score: 0.2027022020808058\n",
      "truth: 175000, predict.: 204006.65674381936, score: 0.15336583800490367\n",
      "truth: 277500, predict.: 291036.89683015284, score: 0.04762895156562941\n",
      "truth: 112500, predict.: 122544.54500293534, score: 0.08552064633426859\n",
      "truth: 263000, predict.: 230096.40572156524, score: 0.1336551120436127\n",
      "truth: 325000, predict.: 318002.6877131224, score: 0.02176527995299793\n",
      "truth: 243000, predict.: 214546.3470419748, score: 0.12453511241768034\n",
      "truth: 130000, predict.: 121462.82132827406, score: 0.06792569113991753\n",
      "truth: 164990, predict.: 190167.21345016302, score: 0.14201808747339584\n",
      "truth: 280000, predict.: 304458.33550984046, score: 0.08374435851688844\n",
      "truth: 403000, predict.: 337478.932943296, score: 0.1774329927340812\n",
      "truth: 119000, predict.: 137076.3982591152, score: 0.1414138206623985\n",
      "truth: 125000, predict.: 131836.5426848779, score: 0.053248690101245444\n",
      "truth: 128200, predict.: 139288.91787198835, score: 0.08295815631274195\n",
      "truth: 172500, predict.: 165896.88821260305, score: 0.03903056571974517\n",
      "truth: 84900, predict.: 102756.18093827664, score: 0.19088286660052312\n",
      "truth: 412500, predict.: 429492.83469776774, score: 0.040368756703491826\n",
      "truth: 156000, predict.: 138834.78802685114, score: 0.11657056383724473\n",
      "truth: 167900, predict.: 160131.642493516, score: 0.047372032617222004\n",
      "truth: 100000, predict.: 78092.97577565508, score: 0.24726726682222555\n",
      "truth: 275000, predict.: 246241.45938925672, score: 0.11045807620977044\n",
      "truth: 123000, predict.: 104435.38781295961, score: 0.16361432842914958\n",
      "truth: 132000, predict.: 126907.65466345563, score: 0.03934192526281777\n",
      "truth: 239900, predict.: 249007.1766979232, score: 0.03725939582935389\n",
      "truth: 139000, predict.: 137499.96197378758, score: 0.010850214094263677\n",
      "truth: 115000, predict.: 94522.71350087262, score: 0.1960900844400495\n",
      "truth: 137500, predict.: 142513.6438215533, score: 0.035813568281451325\n",
      "truth: 135000, predict.: 131802.70979196174, score: 0.023968417014391008\n",
      "truth: 134450, predict.: 130801.05089490424, score: 0.027514701871574232\n",
      "truth: 180500, predict.: 165998.46487959148, score: 0.08375175318936456\n",
      "truth: 193500, predict.: 204023.26628165288, score: 0.052956258715850524\n",
      "truth: 156500, predict.: 158874.8167460912, score: 0.015060470569640216\n",
      "truth: 132000, predict.: 133880.85087134427, score: 0.014148202785497332\n",
      "truth: 224500, predict.: 222353.9353929769, score: 0.009605248299600078\n",
      "truth: 139000, predict.: 128448.68893036537, score: 0.07894382551412704\n",
      "truth: 225000, predict.: 201519.79859552812, score: 0.1102122517425812\n",
      "truth: 188500, predict.: 186389.06456674624, score: 0.011261712763422693\n",
      "truth: 118000, predict.: 124886.74573290818, score: 0.05672220068530898\n",
      "truth: 82000, predict.: 66844.78666765847, score: 0.20434316741195957\n",
      "truth: 392000, predict.: 237646.71661660666, score: 0.5004749959713006\n",
      "truth: 112000, predict.: 85264.43646897106, score: 0.27273862710495855\n",
      "truth: 248900, predict.: 258757.8769182717, score: 0.03884142387837031\n",
      "truth: 134500, predict.: 129610.68739721674, score: 0.0370286735722587\n",
      "truth: 79500, predict.: 98532.92887796085, score: 0.2146313442831147\n",
      "truth: 320000, predict.: 264532.4234782263, score: 0.19035651271688891\n",
      "truth: 158000, predict.: 162218.5419624638, score: 0.0263492529596121\n",
      "truth: 140000, predict.: 133580.79906083384, score: 0.04693554819376011\n",
      "truth: 136500, predict.: 129477.07559701164, score: 0.05282037420802155\n",
      "truth: 107500, predict.: 134268.9776461279, score: 0.22235238175008298\n",
      "truth: 145000, predict.: 149520.60299950003, score: 0.030700245111759727\n",
      "truth: 200500, predict.: 207950.13545164958, score: 0.036483892123369444\n",
      "truth: 185000, predict.: 198420.9120180791, score: 0.07003440192271349\n",
      "truth: 105000, predict.: 93521.26332564531, score: 0.11577035553613513\n",
      "truth: 202665, predict.: 189680.79957849052, score: 0.06621137466222571\n",
      "truth: 186000, predict.: 175334.8280583003, score: 0.05904889760506471\n",
      "truth: 136000, predict.: 141037.40066530948, score: 0.03636995979280577\n",
      "truth: 200500, predict.: 192986.74100281103, score: 0.03819256549798311\n",
      "truth: 190000, predict.: 193291.83971048635, score: 0.01717700785681231\n",
      "truth: 187500, predict.: 187384.7171396725, score: 0.0006150277333958343\n",
      "truth: 200000, predict.: 223582.6821732186, score: 0.11146339432398733\n",
      "truth: 172500, predict.: 203481.9374191565, score: 0.1651791222052399\n",
      "truth: 157000, predict.: 148711.82450032278, score: 0.0542350808896348\n",
      "truth: 213000, predict.: 206966.20967092208, score: 0.0287364872033411\n",
      "truth: 185000, predict.: 198907.46324754204, score: 0.07248350474973186\n",
      "truth: 124500, predict.: 117157.53123994141, score: 0.06078576248109968\n",
      "truth: 162900, predict.: 147597.6282122209, score: 0.09864603615653778\n",
      "truth: 260000, predict.: 242289.03867228926, score: 0.0705499617310732\n",
      "truth: 198500, predict.: 214707.28356485345, score: 0.07848614828656686\n",
      "truth: 120000, predict.: 118579.20854702735, score: 0.011910479099766391\n",
      "truth: 159500, predict.: 152280.65543812158, score: 0.04631838932779431\n",
      "truth: 105900, predict.: 116476.83101100923, score: 0.09519626771357892\n",
      "truth: 260000, predict.: 254954.69550547688, score: 0.019595690214410766\n",
      "truth: 143000, predict.: 155959.207192699, score: 0.08674926937003136\n",
      "truth: 106500, predict.: 99029.31415717311, score: 0.07272836790511583\n",
      "truth: 178900, predict.: 177331.74722032138, score: 0.008804684694466047\n",
      "truth: 127000, predict.: 125383.62937872329, score: 0.01280891249462357\n",
      "truth: 90350, predict.: 105286.57862612334, score: 0.15299336537107422\n",
      "truth: 118500, predict.: 122756.42428673216, score: 0.03528884847509772\n",
      "truth: 190000, predict.: 196101.68236226036, score: 0.031609076347107745\n",
      "truth: 119900, predict.: 134802.41910453065, score: 0.11715116015121474\n",
      "truth: 183900, predict.: 171502.5560161795, score: 0.06979356815414128\n",
      "truth: 155000, predict.: 160082.98065955145, score: 0.032266988143820896\n",
      "truth: 386250, predict.: 429880.8427374009, score: 0.10702296939048317\n",
      "truth: 133000, predict.: 122411.13703733515, score: 0.0829631230264063\n",
      "truth: 193500, predict.: 205984.42952891943, score: 0.06252275543078767\n",
      "truth: 270000, predict.: 268858.1751102676, score: 0.00423793277518314\n",
      "truth: 141000, predict.: 160789.80685981977, score: 0.13133720128914916\n",
      "truth: 146000, predict.: 171665.95609055873, score: 0.16194282695867734\n",
      "truth: 128500, predict.: 127873.59951501209, score: 0.004886593986688226\n",
      "truth: 176000, predict.: 198237.98047752533, score: 0.11898359815779003\n",
      "truth: 214000, predict.: 222527.99201740106, score: 0.03907670641150318\n",
      "truth: 222000, predict.: 230807.19588700944, score: 0.03890515841241893\n",
      "truth: 415298, predict.: 379876.6372612765, score: 0.08914954907809225\n",
      "truth: 187750, predict.: 192266.5516863502, score: 0.023771283514630426\n",
      "truth: 199900, predict.: 200667.3494741505, score: 0.0038312986942621308\n",
      "truth: 180000, predict.: 162458.48083238004, score: 0.1025337844769183\n",
      "truth: 206300, predict.: 225877.82992335176, score: 0.09066243733523116\n",
      "truth: 194000, predict.: 202008.36058979877, score: 0.04045072219180135\n",
      "truth: 142953, predict.: 131705.9074937709, score: 0.0819438441149547\n",
      "truth: 182900, predict.: 177939.4369638662, score: 0.027496152355890757\n",
      "truth: 116050, predict.: 98788.75258677863, score: 0.1610358690414042\n",
      "truth: 213250, predict.: 235273.82338210425, score: 0.09828441636495455\n",
      "truth: 139500, predict.: 145009.51284754553, score: 0.03873447249476136\n",
      "truth: 179000, predict.: 189573.63183153243, score: 0.05739139009489769\n",
      "truth: 107900, predict.: 110773.38277454529, score: 0.026281405124253254\n",
      "truth: 175900, predict.: 168916.5624440679, score: 0.040510537052814044\n",
      "truth: 158500, predict.: 155699.2551416476, score: 0.017828184932408675\n",
      "truth: 145000, predict.: 138085.06441260956, score: 0.04886349301953885\n",
      "truth: 217000, predict.: 229125.69854169182, score: 0.05437315747375848\n",
      "truth: 150500, predict.: 151348.23028610778, score: 0.0056202211146150205\n",
      "truth: 108959, predict.: 152460.29602705812, score: 0.33592992489058915\n",
      "truth: 165600, predict.: 184574.65970726399, score: 0.10847817855477437\n",
      "truth: 201000, predict.: 223665.68232445852, score: 0.10684703513752325\n",
      "truth: 145500, predict.: 144097.51923305145, score: 0.009685732455206875\n",
      "truth: 319900, predict.: 294282.2296929065, score: 0.08346890302587617\n",
      "truth: 215000, predict.: 239374.3930479819, score: 0.10739032262982917\n",
      "truth: 180500, predict.: 152651.2434694127, score: 0.167573902031954\n",
      "truth: 367294, predict.: 392984.67897738767, score: 0.06760783106176405\n",
      "truth: 239000, predict.: 267174.3463074276, score: 0.11143743456895194\n",
      "truth: 145900, predict.: 147157.91445179915, score: 0.008584744041890247\n",
      "truth: 161000, predict.: 183423.65734004785, score: 0.13039342033279055\n",
      "truth: 250000, predict.: 288508.36308365763, score: 0.1432626219300417\n",
      "truth: 89471, predict.: 120889.87776458259, score: 0.30096257486977507\n",
      "truth: 230000, predict.: 218309.7854525989, score: 0.05216398784187248\n",
      "truth: 147000, predict.: 110748.6715300888, score: 0.283166946424112\n",
      "truth: 163900, predict.: 170257.15880160834, score: 0.03805327934534475\n",
      "truth: 97000, predict.: 124086.80830901641, score: 0.24626815879394393\n",
      "truth: 142000, predict.: 135500.47061024886, score: 0.046851606356955955\n",
      "truth: 197000, predict.: 189557.1706417366, score: 0.03851285836444518\n",
      "truth: 129000, predict.: 125075.33933005898, score: 0.030895890737133058\n",
      "truth: 232000, predict.: 241337.5159569873, score: 0.03945889644506728\n",
      "truth: 115000, predict.: 126444.4383299126, score: 0.09487007359569155\n",
      "truth: 175000, predict.: 168106.44998718024, score: 0.04018832997881994\n",
      "truth: 265000, predict.: 272172.76936190575, score: 0.026707120697306408\n",
      "truth: 207000, predict.: 199581.55384398717, score: 0.036495669705548295\n",
      "truth: 181000, predict.: 166024.5082435099, score: 0.08636111544349134\n",
      "truth: 176000, predict.: 188552.75454877966, score: 0.06889345941468328\n",
      "truth: 171000, predict.: 162587.66766740053, score: 0.05044590429627682\n",
      "truth: 196000, predict.: 173820.42578364688, score: 0.12009127763826122\n",
      "truth: 176000, predict.: 170179.99976463674, score: 0.03362710168790706\n",
      "truth: 113000, predict.: 119090.17116254264, score: 0.05249267576520289\n",
      "truth: 139000, predict.: 115950.9605618851, score: 0.18130515510704015\n",
      "truth: 135000, predict.: 136663.064777309, score: 0.012243646815800702\n",
      "truth: 240000, predict.: 223199.40592218415, score: 0.07257304084669691\n",
      "truth: 112000, predict.: 110659.50097708988, score: 0.012040835192811628\n",
      "truth: 134000, predict.: 135184.524108014, score: 0.008800825059811501\n",
      "truth: 316600, predict.: 277142.0855465831, score: 0.13310837886274385\n",
      "truth: 170000, predict.: 208290.95392136596, score: 0.20313640077714723\n",
      "truth: 116000, predict.: 108023.04643802643, score: 0.07124495721401836\n",
      "truth: 306000, predict.: 306537.94805480604, score: 0.001756450970479051\n",
      "truth: 82500, predict.: 111099.1837386568, score: 0.2976219359782135\n",
      "truth: 175000, predict.: 171156.90696797476, score: 0.022205125230536638\n",
      "truth: 106000, predict.: 100269.48092116996, score: 0.05557718424370783\n",
      "truth: 194000, predict.: 200978.33184617318, score: 0.035338762446881944\n",
      "truth: 194201, predict.: 209721.0159915976, score: 0.07688406596978581\n",
      "truth: 155900, predict.: 139154.60020583792, score: 0.1136284574293942\n",
      "truth: 138000, predict.: 144871.19038975227, score: 0.04859097662330569\n",
      "truth: 177000, predict.: 170542.11370641226, score: 0.0371672512038419\n",
      "truth: 214000, predict.: 201974.54974100922, score: 0.0578340387190579\n",
      "truth: 148000, predict.: 131045.86142829603, score: 0.12166405043704742\n",
      "truth: 127000, predict.: 114375.36717786382, score: 0.1047004834514329\n",
      "truth: 142500, predict.: 146840.0930158344, score: 0.030001984956713912\n",
      "truth: 80000, predict.: 84151.99353563963, score: 0.05059735921271802\n",
      "truth: 145000, predict.: 145108.96940774098, score: 0.0007512257332979999\n",
      "truth: 171000, predict.: 167644.97849567936, score: 0.01981491931392121\n",
      "truth: 122500, predict.: 118912.02968562552, score: 0.02972681027909907\n",
      "truth: 139000, predict.: 129954.11410930763, score: 0.06729201259759598\n",
      "truth: 189000, predict.: 197735.85644903904, score: 0.045184832896314475\n",
      "truth: 120500, predict.: 115213.2705214982, score: 0.04486443500700332\n",
      "truth: 124000, predict.: 117254.26730571428, score: 0.055936300055186905\n",
      "truth: 160000, predict.: 148060.629518843, score: 0.07755146245926525\n",
      "truth: 200000, predict.: 167432.75153056582, score: 0.1777346067567631\n",
      "truth: 160000, predict.: 150749.63971614806, score: 0.05955298605946702\n",
      "truth: 313000, predict.: 322513.7886808693, score: 0.02994260613601618\n",
      "truth: 275000, predict.: 268863.0628657401, score: 0.022568824656858055\n",
      "truth: 67000, predict.: 58193.704211844735, score: 0.14091318697906274\n",
      "truth: 159000, predict.: 154561.12892036096, score: 0.028314347068624457\n",
      "truth: 251000, predict.: 261145.7036492699, score: 0.0396254091730448\n",
      "truth: 92900, predict.: 89996.65336503205, score: 0.031750813756033835\n",
      "truth: 109500, predict.: 94439.71551373013, score: 0.1479613930620669\n",
      "truth: 385000, predict.: 409800.2179167831, score: 0.06242627609185902\n",
      "truth: 129000, predict.: 194241.50690010833, score: 0.4092872577173132\n",
      "truth: 82500, predict.: 183473.41226718246, score: 0.7992648006066396\n",
      "truth: 301000, predict.: 289092.8438770435, score: 0.04036223230223435\n",
      "truth: 249700, predict.: 248733.33556352992, score: 0.0038788006365564343\n",
      "truth: 81000, predict.: 78717.314826931, score: 0.028585654938597216\n",
      "truth: 187500, predict.: 207513.77504872068, score: 0.10141836346029187\n",
      "truth: 110000, predict.: 132525.87587508984, score: 0.1862960049906217\n",
      "truth: 117000, predict.: 145560.52579356494, score: 0.21841637315038476\n",
      "truth: 128500, predict.: 122744.14983176278, score: 0.04582643308437184\n",
      "truth: 213490, predict.: 199198.09925739098, score: 0.06928985387337683\n",
      "truth: 284000, predict.: 274234.14283569535, score: 0.034991835392622406\n",
      "truth: 230500, predict.: 233454.99456737525, score: 0.0127383984291356\n",
      "truth: 190000, predict.: 211863.61619901977, score: 0.10891813253902782\n",
      "truth: 135000, predict.: 132398.3325699705, score: 0.01945958334050779\n",
      "truth: 152000, predict.: 169568.29439488606, score: 0.10937455999481216\n",
      "truth: 87500, predict.: 83400.16759817883, score: 0.04798791262482638\n",
      "truth: 155000, predict.: 167377.17043208197, score: 0.07682417740921288\n",
      "truth: 115000, predict.: 97932.77498261904, score: 0.16064933922293534\n",
      "truth: 144000, predict.: 142643.27133778748, score: 0.009466326009055948\n",
      "truth: 248000, predict.: 249102.38759706315, score: 0.004435243106645004\n",
      "truth: 132500, predict.: 126817.97768200979, score: 0.043829495501453763\n",
      "truth: 136000, predict.: 136247.26114146918, score: 0.001816432547272484\n",
      "truth: 117000, predict.: 118825.22628285487, score: 0.015479660751564595\n",
      "truth: 82000, predict.: 92336.83863971944, score: 0.11872256794897851\n",
      "truth: 157500, predict.: 159506.43340134705, score: 0.012658718084226805\n",
      "truth: 110000, predict.: 107083.79820967102, score: 0.02686842943340295\n",
      "truth: 181000, predict.: 199682.6194106238, score: 0.09823165495915198\n",
      "truth: 192500, predict.: 198691.33588458423, score: 0.03165622900387177\n",
      "truth: 223500, predict.: 213720.06866761338, score: 0.044744140923111075\n",
      "truth: 181500, predict.: 177690.8995018366, score: 0.02121001445574855\n",
      "truth: 170000, predict.: 173253.06976439533, score: 0.01895480911178815\n",
      "truth: 187500, predict.: 202719.57070603277, score: 0.07804435308215041\n",
      "truth: 185900, predict.: 195685.29181752438, score: 0.05129855107836789\n",
      "truth: 160000, predict.: 140622.84794931143, score: 0.12909148464962072\n",
      "truth: 192000, predict.: 205329.47953598606, score: 0.06712019605757114\n",
      "truth: 181900, predict.: 180102.53462772415, score: 0.009930705128351036\n",
      "truth: 266000, predict.: 266269.0824760375, score: 0.001011073146070629\n",
      "truth: 99900, predict.: 86109.8634941775, score: 0.14854411915291088\n",
      "truth: 438780, predict.: 455290.0599496338, score: 0.036936479077343876\n",
      "truth: 229456, predict.: 249476.8129004493, score: 0.08365433687531443\n",
      "truth: 216837, predict.: 210632.4709844135, score: 0.02903101233756722\n",
      "truth: 110500, predict.: 91202.7051338016, score: 0.19192904796843813\n",
      "truth: 175900, predict.: 222668.08452605412, score: 0.23576540668384816\n",
      "truth: 538000, predict.: 428018.7633404499, score: 0.22869104835131004\n",
      "truth: 160000, predict.: 273917.5957671368, score: 0.5376509012917161\n",
      "truth: 172500, predict.: 199514.0023640281, score: 0.14548639976618283\n",
      "truth: 108000, predict.: 122750.24079710468, score: 0.12801938860964768\n",
      "truth: 131500, predict.: 134086.80303345041, score: 0.019480375737286337\n",
      "truth: 106250, predict.: 96012.23407019576, score: 0.10131818266034642\n",
      "truth: 385000, predict.: 384184.25927457074, score: 0.0021210494114214384\n",
      "truth: 370878, predict.: 379395.2563053504, score: 0.02270532618624088\n",
      "truth: 345000, predict.: 359641.3359769303, score: 0.041562710837721895\n",
      "truth: 68500, predict.: 68739.64671836483, score: 0.0034923358567056084\n",
      "truth: 250000, predict.: 232798.0237821077, score: 0.07128939538158185\n",
      "truth: 245350, predict.: 263165.9248755945, score: 0.07009868785065265\n",
      "truth: 125000, predict.: 142888.3947547943, score: 0.13374913045938897\n",
      "truth: 234000, predict.: 234447.6531371785, score: 0.0019112118898743091\n",
      "truth: 145000, predict.: 133070.38109789742, score: 0.08585495471449889\n",
      "truth: 181000, predict.: 186213.05860838102, score: 0.028394308610632635\n",
      "truth: 104000, predict.: 137994.6233447672, score: 0.2828214552815247\n",
      "truth: 233000, predict.: 229424.4000695806, score: 0.015464822905988385\n",
      "truth: 164000, predict.: 219243.5434067451, score: 0.2903152180355075\n",
      "truth: 219500, predict.: 186406.41037996847, score: 0.16342213159489205\n",
      "truth: 195000, predict.: 222666.23939781188, score: 0.13267377025536398\n",
      "truth: 108000, predict.: 104151.76296178155, score: 0.03628179030781986\n",
      "truth: 149900, predict.: 133358.687219786, score: 0.11692518314311684\n",
      "truth: 315000, predict.: 345469.5324284473, score: 0.09233153650388815\n",
      "truth: 177500, predict.: 172178.18535031917, score: 0.03044053286770776\n",
      "truth: 140000, predict.: 139463.1833075562, score: 0.0038417476290319996\n",
      "truth: 193879, predict.: 194728.65415036766, score: 0.004372796687734493\n",
      "truth: 137900, predict.: 131766.79987037688, score: 0.045494754728279574\n",
      "truth: 118000, predict.: 117167.39521200515, score: 0.007080923655951921\n",
      "truth: 324000, predict.: 284452.3778772469, score: 0.13017723596341035\n",
      "truth: 555000, predict.: 486403.2823334778, score: 0.13192978079386108\n",
      "truth: 136000, predict.: 188004.46417836682, score: 0.32380878853592776\n",
      "truth: 82500, predict.: 80771.76183592076, score: 0.02117061177632351\n",
      "truth: 101000, predict.: 96389.3555127228, score: 0.04672426771935356\n",
      "truth: 314813, predict.: 317468.77633804444, score: 0.008400632930124274\n",
      "truth: 109500, predict.: 100550.11231875136, score: 0.08526750313285447\n",
      "truth: 163500, predict.: 142450.11646699306, score: 0.13782020800722172\n",
      "truth: 271000, predict.: 284723.54562449286, score: 0.04939969540947686\n",
      "truth: 205000, predict.: 221745.154702989, score: 0.07851842317854008\n",
      "truth: 185000, predict.: 187292.8537675769, score: 0.012317563533674303\n",
      "truth: 160000, predict.: 141327.61966098382, score: 0.12409225066192242\n",
      "truth: 155000, predict.: 165449.53883844026, score: 0.06524072265629854\n",
      "truth: 91000, predict.: 93902.753488224, score: 0.03139986319837007\n",
      "truth: 131000, predict.: 128323.3858485275, score: 0.02064363423155058\n",
      "truth: 165400, predict.: 177550.39766796198, score: 0.070887302805831\n",
      "truth: 194700, predict.: 166057.14470081474, score: 0.159127052163198\n",
      "truth: 155000, predict.: 164281.37673611898, score: 0.05815518806500464\n",
      "truth: 140000, predict.: 144402.9074552006, score: 0.03096472059073818\n",
      "truth: 147000, predict.: 143589.515018771, score: 0.02347378644536846\n",
      "truth: 194000, predict.: 201599.36657567718, score: 0.03842404083807338\n",
      "truth: 179540, predict.: 175916.79198961073, score: 0.02038679915342989\n",
      "truth: 173000, predict.: 184161.3567254574, score: 0.06252036722635879\n",
      "truth: 109500, predict.: 102222.52525063077, score: 0.06877184199228203\n",
      "truth: 173733, predict.: 168256.9837564122, score: 0.03202697472784344\n",
      "truth: 129900, predict.: 141487.04636405196, score: 0.0854426136459292\n",
      "truth: 119000, predict.: 120261.76099065314, score: 0.010547127422315228\n",
      "truth: 125500, predict.: 124533.3862882644, score: 0.007731853811201006\n",
      "truth: 149300, predict.: 141916.27785427246, score: 0.050720064915488194\n",
      "truth: 305000, predict.: 301920.93098676426, score: 0.010146578000641782\n",
      "truth: 102000, predict.: 124606.1557347028, score: 0.20018341719906196\n",
      "truth: 178740, predict.: 175721.8156481948, score: 0.01702998818394974\n",
      "truth: 129500, predict.: 178229.63415177405, score: 0.3193898059648621\n",
      "truth: 79900, predict.: 107967.04845705377, score: 0.3010469673943419\n",
      "truth: 278000, predict.: 259490.0270241419, score: 0.06890258674000727\n",
      "truth: 118400, predict.: 111119.92617225676, score: 0.06345813506531073\n",
      "truth: 197000, predict.: 240975.40102101146, score: 0.20149020275419538\n",
      "truth: 140000, predict.: 146903.87626787074, score: 0.04813571165952091\n",
      "truth: 226000, predict.: 234087.085613948, score: 0.035158054730489496\n",
      "truth: 132500, predict.: 123274.77591976106, score: 0.0721662662589253\n",
      "truth: 315000, predict.: 369834.4099994448, score: 0.16048225540545857\n",
      "truth: 224000, predict.: 213229.14106420803, score: 0.04927845923394791\n",
      "truth: 132500, predict.: 137729.60296012447, score: 0.03870943219365586\n",
      "truth: 119500, predict.: 121937.70101939693, score: 0.020193728264555233\n",
      "truth: 215000, predict.: 232888.3685626162, score: 0.07992084849067815\n",
      "truth: 210000, predict.: 164181.2439394164, score: 0.24613523822773153\n",
      "truth: 200141, predict.: 194630.37127675553, score: 0.027919748830630198\n",
      "truth: 185000, predict.: 151550.61005233641, score: 0.1994350031198202\n",
      "truth: 149900, predict.: 147661.8084710182, score: 0.015043722900454526\n",
      "truth: 129000, predict.: 124116.0042215956, score: 0.03859545312641366\n",
      "truth: 184100, predict.: 208293.19862108838, score: 0.12346697674932372\n",
      "truth: 135000, predict.: 140989.4279665381, score: 0.043409815493214765\n",
      "truth: 128000, predict.: 123668.0756992908, score: 0.03442882259133384\n",
      "truth: 374000, predict.: 358868.62403053435, score: 0.04129931293992861\n",
      "truth: 164000, predict.: 166010.42104718977, score: 0.012184062112341465\n",
      "truth: 157000, predict.: 170655.12811222058, score: 0.08339841036759665\n",
      "truth: 215000, predict.: 221572.0308610069, score: 0.030109566296452783\n",
      "truth: 165000, predict.: 164560.2223806383, score: 0.0026688609951897035\n",
      "truth: 144000, predict.: 135070.5559053357, score: 0.064015562238243\n",
      "truth: 125500, predict.: 106478.7581362376, score: 0.16435882403111357\n",
      "truth: 98300, predict.: 91755.00040604138, score: 0.0689013157242453\n",
      "truth: 91300, predict.: 93858.79008840726, score: 0.02764033348740469\n",
      "truth: 135960, predict.: 130711.61443465347, score: 0.03936694951265984\n",
      "truth: 226700, predict.: 217402.7450624616, score: 0.04187576748277522\n",
      "truth: 333168, predict.: 351806.1896191929, score: 0.05443340001132846\n",
      "truth: 114500, predict.: 112227.55090620885, score: 0.02004613145787637\n",
      "truth: 97000, predict.: 86687.23081404346, score: 0.11240315924589517\n",
      "truth: 181000, predict.: 158079.87321621872, score: 0.13539579824011838\n",
      "truth: 465000, predict.: 427158.49637370073, score: 0.08488208483093729\n",
      "truth: 290000, predict.: 312949.6497088193, score: 0.07616113819678816\n",
      "truth: 175000, predict.: 154754.26042255253, score: 0.12294678416845173\n",
      "truth: 235000, predict.: 312823.0890064549, score: 0.2860512471419163\n",
      "truth: 277000, predict.: 259776.4505333782, score: 0.06419581130310448\n",
      "truth: 325000, predict.: 370888.6037111469, score: 0.13207619495747025\n",
      "truth: 178000, predict.: 180258.31851597858, score: 0.012607304305754852\n",
      "truth: 235000, predict.: 234159.5764185581, score: 0.0035826654296577942\n",
      "truth: 239000, predict.: 252503.4181404072, score: 0.05496101012492893\n",
      "truth: 85000, predict.: 94777.11676229184, score: 0.10887552564648395\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "prediction = grid.predict(X_test)\n",
    "\n",
    "for t,p in zip(y_test, prediction):\n",
    "    print(\"truth: {}, predict.: {}, score: {}\".format(t, p, sqrt(mean_squared_log_error([t], [p]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the subset of records where the score is higher than 0.1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y_test)\n",
    "p = pd.DataFrame(prediction, columns=['Prediction'])\n",
    "result = pd.concat([X_test, y], axis=1)\n",
    "result['Prediction'] = prediction\n",
    "\n",
    "def msle(row):\n",
    "    return sqrt(mean_squared_log_error([row['SalePrice']], [row['Prediction']]))\n",
    "\n",
    "result['Score'] = result.apply(msle, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>MSZoning_C (all)</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_StoneBr</th>\n",
       "      <th>Condition1_Norm</th>\n",
       "      <th>Exterior1st_BrkFace</th>\n",
       "      <th>Functional_Typ</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>BsmtFinSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>50.0</td>\n",
       "      <td>9100</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1930</td>\n",
       "      <td>1960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>70.0</td>\n",
       "      <td>7000</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1910</td>\n",
       "      <td>1991</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>60.0</td>\n",
       "      <td>12900</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1969</td>\n",
       "      <td>1969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5925</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1937</td>\n",
       "      <td>2000</td>\n",
       "      <td>435.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>70.0</td>\n",
       "      <td>10500</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1971</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>102.0</td>\n",
       "      <td>10192</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1968</td>\n",
       "      <td>1992</td>\n",
       "      <td>143.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12342</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1940</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18450</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1965</td>\n",
       "      <td>1979</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>85.0</td>\n",
       "      <td>11900</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1977</td>\n",
       "      <td>1977</td>\n",
       "      <td>209.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>59.0</td>\n",
       "      <td>5310</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1910</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>51.0</td>\n",
       "      <td>3635</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>130.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>313.0</td>\n",
       "      <td>63887</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>796.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>92.0</td>\n",
       "      <td>5520</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1912</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>152.0</td>\n",
       "      <td>12134</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1988</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>60.0</td>\n",
       "      <td>8520</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1916</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>67.0</td>\n",
       "      <td>8877</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1951</td>\n",
       "      <td>1951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1917</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>60.0</td>\n",
       "      <td>5586</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1920</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>102.0</td>\n",
       "      <td>15863</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1920</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4750</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>481.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "589          50.0     9100            5            6       1930          1960   \n",
       "535          70.0     7000            5            7       1910          1991   \n",
       "1163         60.0    12900            4            4       1969          1969   \n",
       "479          50.0     5925            4            7       1937          2000   \n",
       "223          70.0    10500            4            6       1971          1971   \n",
       "1355        102.0    10192            7            6       1968          1992   \n",
       "308           0.0    12342            4            5       1940          1950   \n",
       "666           0.0    18450            6            5       1965          1979   \n",
       "632          85.0    11900            7            5       1977          1977   \n",
       "986          59.0     5310            6            8       1910          2003   \n",
       "1415         51.0     3635            7            5       2007          2007   \n",
       "1298        313.0    63887           10            5       2008          2008   \n",
       "198          92.0     5520            6            6       1912          1950   \n",
       "1211        152.0    12134            8            7       1988          2005   \n",
       "1387         60.0     8520            6            7       1916          1950   \n",
       "771          67.0     8877            4            5       1951          1951   \n",
       "1248         60.0     9600            6            5       1917          1950   \n",
       "431          60.0     5586            6            7       1920          1998   \n",
       "1031        102.0    15863            7            3       1920          1970   \n",
       "251          44.0     4750            8            5       2006          2007   \n",
       "\n",
       "      MasVnrArea  ExterQual  BsmtQual  BsmtExposure    ...      ScreenPorch  \\\n",
       "589          0.0          3         3             0    ...                0   \n",
       "535          0.0          3         4             4    ...                0   \n",
       "1163         0.0          3         4             3    ...                0   \n",
       "479        435.0          3         2             0    ...                0   \n",
       "223          0.0          3         3             0    ...                0   \n",
       "1355       143.0          3         3             0    ...                0   \n",
       "308          0.0          3         3             0    ...                0   \n",
       "666        113.0          3         4             0    ...                0   \n",
       "632        209.0          3         3             0    ...                0   \n",
       "986          0.0          3         3             0    ...                0   \n",
       "1415       130.0          4         4             0    ...                0   \n",
       "1298       796.0          5         5             4    ...                0   \n",
       "198          0.0          3         3             0    ...                0   \n",
       "1211         0.0          4         4             3    ...                0   \n",
       "1387         0.0          3         3             0    ...                0   \n",
       "771          0.0          3         2             0    ...                0   \n",
       "1248         0.0          3         4             0    ...                0   \n",
       "431          0.0          3         3             0    ...                0   \n",
       "1031         0.0          3         3             0    ...                0   \n",
       "251        481.0          4         4             4    ...              153   \n",
       "\n",
       "      MSZoning_C (all)  Neighborhood_Crawfor  Neighborhood_StoneBr  \\\n",
       "589                  0                     0                     0   \n",
       "535                  0                     0                     0   \n",
       "1163                 0                     0                     0   \n",
       "479                  0                     0                     0   \n",
       "223                  0                     0                     0   \n",
       "1355                 0                     0                     0   \n",
       "308                  0                     0                     0   \n",
       "666                  0                     0                     0   \n",
       "632                  0                     0                     0   \n",
       "986                  0                     0                     0   \n",
       "1415                 0                     0                     0   \n",
       "1298                 0                     0                     0   \n",
       "198                  0                     0                     0   \n",
       "1211                 0                     0                     0   \n",
       "1387                 0                     0                     0   \n",
       "771                  0                     0                     0   \n",
       "1248                 0                     0                     0   \n",
       "431                  0                     0                     0   \n",
       "1031                 0                     0                     0   \n",
       "251                  0                     1                     0   \n",
       "\n",
       "      Condition1_Norm  Exterior1st_BrkFace  Functional_Typ  SaleType_New  \\\n",
       "589                 0                    0               1             0   \n",
       "535                 1                    0               1             0   \n",
       "1163                0                    0               1             0   \n",
       "479                 1                    0               1             0   \n",
       "223                 1                    0               1             0   \n",
       "1355                1                    0               1             0   \n",
       "308                 1                    0               1             0   \n",
       "666                 1                    0               0             0   \n",
       "632                 1                    0               1             0   \n",
       "986                 0                    0               1             0   \n",
       "1415                1                    0               1             0   \n",
       "1298                0                    0               1             1   \n",
       "198                 1                    0               1             0   \n",
       "1211                1                    0               1             0   \n",
       "1387                0                    0               1             0   \n",
       "771                 1                    0               1             0   \n",
       "1248                1                    0               1             0   \n",
       "431                 0                    0               1             0   \n",
       "1031                1                    0               1             0   \n",
       "251                 1                    0               1             0   \n",
       "\n",
       "      SaleCondition_Abnorml  BsmtFinSF  \n",
       "589                       0          0  \n",
       "535                       0        969  \n",
       "1163                      0       1198  \n",
       "479                       0        168  \n",
       "223                       1        704  \n",
       "1355                      0          0  \n",
       "308                       0        262  \n",
       "666                       1        910  \n",
       "632                       0        822  \n",
       "986                       0          0  \n",
       "1415                      0        988  \n",
       "1298                      0       5644  \n",
       "198                       1          0  \n",
       "1211                      0        427  \n",
       "1387                      0        714  \n",
       "771                       0        836  \n",
       "1248                      0        319  \n",
       "431                       1          0  \n",
       "1031                      0        523  \n",
       "251                       0       1573  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[(result['Score'] >= 0.2) & (result['SalePrice'] < result['Prediction'])][X_test.columns[mask_rfecv]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>MSZoning_C (all)</th>\n",
       "      <th>Neighborhood_Crawfor</th>\n",
       "      <th>Neighborhood_StoneBr</th>\n",
       "      <th>Condition1_Norm</th>\n",
       "      <th>Exterior1st_BrkFace</th>\n",
       "      <th>Functional_Typ</th>\n",
       "      <th>SaleType_New</th>\n",
       "      <th>SaleCondition_Abnorml</th>\n",
       "      <th>BsmtFinSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>160.0</td>\n",
       "      <td>15623</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>1996</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>71.0</td>\n",
       "      <td>8520</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>80.0</td>\n",
       "      <td>11844</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008</td>\n",
       "      <td>464.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7446</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1941</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>74.0</td>\n",
       "      <td>10206</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1952</td>\n",
       "      <td>1952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>60.0</td>\n",
       "      <td>8089</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8926</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1956</td>\n",
       "      <td>1956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>70.0</td>\n",
       "      <td>8402</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>47.0</td>\n",
       "      <td>53504</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>603.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>70.0</td>\n",
       "      <td>8737</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1923</td>\n",
       "      <td>1950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "1182        160.0    15623           10            5       1996          1996   \n",
       "142          71.0     8520            5            4       1952          1952   \n",
       "678          80.0    11844            8            5       2008          2008   \n",
       "393           0.0     7446            4            5       1941          1950   \n",
       "1000         74.0    10206            3            3       1952          1952   \n",
       "688          60.0     8089            8            6       2007          2007   \n",
       "1122          0.0     8926            4            3       1956          1956   \n",
       "613          70.0     8402            5            5       2007          2007   \n",
       "769          47.0    53504            8            5       2003          2003   \n",
       "546          70.0     8737            6            7       1923          1950   \n",
       "\n",
       "      MasVnrArea  ExterQual  BsmtQual  BsmtExposure    ...      ScreenPorch  \\\n",
       "1182         0.0          4         5             3    ...                0   \n",
       "142          0.0          3         3             0    ...                0   \n",
       "678        464.0          4         5             1    ...                0   \n",
       "393          0.0          3         3             0    ...                0   \n",
       "1000         0.0          3         0             0    ...                0   \n",
       "688          0.0          4         4             3    ...                0   \n",
       "1122         0.0          3         3             0    ...              160   \n",
       "613          0.0          3         4             0    ...                0   \n",
       "769        603.0          5         4             4    ...              210   \n",
       "546          0.0          3         4             0    ...                0   \n",
       "\n",
       "      MSZoning_C (all)  Neighborhood_Crawfor  Neighborhood_StoneBr  \\\n",
       "1182                 0                     0                     0   \n",
       "142                  0                     0                     0   \n",
       "678                  0                     0                     1   \n",
       "393                  0                     0                     0   \n",
       "1000                 0                     0                     0   \n",
       "688                  0                     0                     1   \n",
       "1122                 0                     0                     0   \n",
       "613                  0                     0                     0   \n",
       "769                  0                     0                     1   \n",
       "546                  0                     0                     0   \n",
       "\n",
       "      Condition1_Norm  Exterior1st_BrkFace  Functional_Typ  SaleType_New  \\\n",
       "1182                1                    0               1             0   \n",
       "142                 0                    1               1             0   \n",
       "678                 1                    0               1             1   \n",
       "393                 0                    0               1             0   \n",
       "1000                1                    0               0             0   \n",
       "688                 1                    0               1             1   \n",
       "1122                1                    0               1             0   \n",
       "613                 0                    0               1             1   \n",
       "769                 1                    0               0             0   \n",
       "546                 1                    1               1             0   \n",
       "\n",
       "      SaleCondition_Abnorml  BsmtFinSF  \n",
       "1182                      1       2096  \n",
       "142                       0        507  \n",
       "678                       0          0  \n",
       "393                       1        266  \n",
       "1000                      0          0  \n",
       "688                       0        945  \n",
       "1122                      1          0  \n",
       "613                       0        206  \n",
       "769                       0       1416  \n",
       "546                       0        300  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[(result['Score'] >= 0.2) & (result['SalePrice'] > result['Prediction'])][X_test.columns[mask_rfecv]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in most cases the Prediction is too high. Let's check if a different model would be able to perform better on this set of test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score-gbr: 0.5095551195258459, score-lasso: 0.48132525736244425\n",
      "score-gbr: 0.253986064146531, score-lasso: 0.18028837241712026\n",
      "score-gbr: 0.2027022020808058, score-lasso: 0.08226160115742864\n",
      "score-gbr: 0.24726726682222555, score-lasso: 0.5771497465329283\n",
      "score-gbr: 0.20434316741195957, score-lasso: 0.8912464299537373\n",
      "score-gbr: 0.5004749959713006, score-lasso: 0.29092881740443666\n",
      "score-gbr: 0.27273862710495855, score-lasso: 0.6162200937705151\n",
      "score-gbr: 0.2146313442831147, score-lasso: 0.049880758273772585\n",
      "score-gbr: 0.22235238175008298, score-lasso: 0.3576178932817271\n",
      "score-gbr: 0.33592992489058915, score-lasso: 0.17783630632239067\n",
      "score-gbr: 0.30096257486977507, score-lasso: 0.3565740695985369\n",
      "score-gbr: 0.283166946424112, score-lasso: 0.0652167706304958\n",
      "score-gbr: 0.24626815879394393, score-lasso: 0.060072880830004394\n",
      "score-gbr: 0.20313640077714723, score-lasso: 0.15878936198813776\n",
      "score-gbr: 0.2976219359782135, score-lasso: 0.07556615557948376\n",
      "score-gbr: 0.4092872577173132, score-lasso: 0.410259384382865\n",
      "score-gbr: 0.7992648006066396, score-lasso: 0.8446791953213229\n",
      "score-gbr: 0.21841637315038476, score-lasso: 0.19265244723100317\n",
      "score-gbr: 0.23576540668384816, score-lasso: 0.26705560888684765\n",
      "score-gbr: 0.22869104835131004, score-lasso: 0.18110524532969485\n",
      "score-gbr: 0.5376509012917161, score-lasso: 1.553681913405427\n",
      "score-gbr: 0.2828214552815247, score-lasso: 0.3970950146132264\n",
      "score-gbr: 0.2903152180355075, score-lasso: 0.3403224317005744\n",
      "score-gbr: 0.32380878853592776, score-lasso: 0.38619098225384363\n",
      "score-gbr: 0.20018341719906196, score-lasso: 0.09872215841335219\n",
      "score-gbr: 0.3193898059648621, score-lasso: 0.2765560959627056\n",
      "score-gbr: 0.3010469673943419, score-lasso: 0.22783153183822336\n",
      "score-gbr: 0.20149020275419538, score-lasso: 0.21785502223177566\n",
      "score-gbr: 0.24613523822773153, score-lasso: 0.1521258709417186\n",
      "score-gbr: 0.2860512471419163, score-lasso: 0.24096367714042088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "prediction = grid.predict(X_test)\n",
    "\n",
    "\n",
    "lasso = Lasso(alpha=0.01, max_iter=50000)\n",
    "lasso.fit(X_train[X_train.columns[mask_rfecv]], y_train)\n",
    "lasso_predict = lasso.predict(result[(result['Score'] >= 0.2)][X_test.columns[mask_rfecv]])\n",
    "\n",
    "for t,p,l in zip(result[(result['Score'] >= 0.2)]['SalePrice'], result[(result['Score'] >= 0.2)]['Score'], lasso_predict):\n",
    "    print(\"score-gbr: {}, score-lasso: {}\".format(p, sqrt(mean_squared_log_error([t], [l]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbr: 212339.163, lasso: 252751.015, real: 200624\n",
      "gbr: 145334.060, lasso: 132762.461, real: 133000\n",
      "gbr: 104717.116, lasso: 117154.070, real: 110000\n",
      "gbr: 213697.336, lasso: 217139.176, real: 192000\n",
      "gbr: 94141.731, lasso: 112028.475, real: 88000\n",
      "gbr: 99724.939, lasso: 85107.398, real: 85000\n",
      "gbr: 271499.678, lasso: 237172.644, real: 282922\n",
      "gbr: 138670.645, lasso: 151315.042, real: 141000\n",
      "gbr: 447567.877, lasso: 460382.714, real: 745000\n",
      "gbr: 158243.211, lasso: 155757.299, real: 148800\n",
      "gbr: 201292.972, lasso: 212719.562, real: 208900\n",
      "gbr: 142123.881, lasso: 147771.639, real: 136905\n",
      "gbr: 229588.801, lasso: 233534.716, real: 225000\n",
      "gbr: 122153.987, lasso: 119509.262, real: 123000\n",
      "gbr: 120798.123, lasso: 118415.030, real: 119200\n",
      "gbr: 149172.522, lasso: 141668.200, real: 145000\n",
      "gbr: 228593.854, lasso: 229500.024, real: 190000\n",
      "gbr: 128000.992, lasso: 110442.132, real: 123600\n",
      "gbr: 130612.591, lasso: 122366.907, real: 149350\n",
      "gbr: 175312.008, lasso: 186293.802, real: 155000\n",
      "gbr: 128766.409, lasso: 138614.712, real: 166000\n",
      "gbr: 143760.545, lasso: 169907.269, real: 144500\n",
      "gbr: 128150.119, lasso: 104821.865, real: 110000\n",
      "gbr: 159886.982, lasso: 145349.764, real: 174000\n",
      "gbr: 188685.215, lasso: 212816.966, real: 185000\n",
      "gbr: 184590.966, lasso: 206390.372, real: 168000\n",
      "gbr: 166200.438, lasso: 177720.778, real: 177500\n",
      "gbr: 77132.274, lasso: 90163.213, real: 84500\n",
      "gbr: 386572.882, lasso: 313324.399, real: 320000\n",
      "gbr: 108371.340, lasso: 103945.658, real: 118500\n",
      "gbr: 124316.652, lasso: 162413.928, real: 110000\n",
      "gbr: 198476.211, lasso: 216462.823, real: 213000\n",
      "gbr: 144088.335, lasso: 148685.449, real: 156000\n",
      "gbr: 290522.046, lasso: 291332.176, real: 250000\n",
      "gbr: 304154.024, lasso: 343083.963, real: 372500\n",
      "gbr: 204006.657, lasso: 191586.382, real: 175000\n",
      "gbr: 291036.897, lasso: 282200.044, real: 277500\n",
      "gbr: 122544.545, lasso: 111732.509, real: 112500\n",
      "gbr: 230096.406, lasso: 229900.365, real: 263000\n",
      "gbr: 318002.688, lasso: 318334.741, real: 325000\n",
      "gbr: 214546.347, lasso: 229624.257, real: 243000\n",
      "gbr: 121462.821, lasso: 118745.075, real: 130000\n",
      "gbr: 190167.213, lasso: 215739.564, real: 164990\n",
      "gbr: 304458.336, lasso: 279056.745, real: 280000\n",
      "gbr: 337478.933, lasso: 333144.667, real: 403000\n",
      "gbr: 137076.398, lasso: 148007.907, real: 119000\n",
      "gbr: 131836.543, lasso: 117182.672, real: 125000\n",
      "gbr: 139288.918, lasso: 131716.868, real: 128200\n",
      "gbr: 165896.888, lasso: 179111.686, real: 172500\n",
      "gbr: 102756.181, lasso: 73244.905, real: 84900\n",
      "gbr: 429492.835, lasso: 363978.985, real: 412500\n",
      "gbr: 138834.788, lasso: 143306.434, real: 156000\n",
      "gbr: 160131.642, lasso: 180153.257, real: 167900\n",
      "gbr: 78092.976, lasso: 56149.211, real: 100000\n",
      "gbr: 246241.459, lasso: 259041.481, real: 275000\n",
      "gbr: 104435.388, lasso: 92458.182, real: 123000\n",
      "gbr: 126907.655, lasso: 108747.598, real: 132000\n",
      "gbr: 249007.177, lasso: 230561.120, real: 239900\n",
      "gbr: 137499.962, lasso: 118972.873, real: 139000\n",
      "gbr: 94522.714, lasso: 80865.063, real: 115000\n",
      "gbr: 142513.644, lasso: 147074.960, real: 137500\n",
      "gbr: 131802.710, lasso: 119554.428, real: 135000\n",
      "gbr: 130801.051, lasso: 130168.323, real: 134450\n",
      "gbr: 165998.465, lasso: 165207.590, real: 180500\n",
      "gbr: 204023.266, lasso: 216224.318, real: 193500\n",
      "gbr: 158874.817, lasso: 183028.586, real: 156500\n",
      "gbr: 133880.851, lasso: 117722.646, real: 132000\n",
      "gbr: 222353.935, lasso: 228873.623, real: 224500\n",
      "gbr: 128448.689, lasso: 143388.353, real: 139000\n",
      "gbr: 201519.799, lasso: 209815.777, real: 225000\n",
      "gbr: 186389.065, lasso: 192286.460, real: 188500\n",
      "gbr: 124886.746, lasso: 105276.875, real: 118000\n",
      "gbr: 66844.787, lasso: 33631.236, real: 82000\n",
      "gbr: 237646.717, lasso: 293046.752, real: 392000\n",
      "gbr: 85264.436, lasso: 60477.486, real: 112000\n",
      "gbr: 258757.877, lasso: 280978.473, real: 248900\n",
      "gbr: 129610.687, lasso: 123284.637, real: 134500\n",
      "gbr: 98532.929, lasso: 75631.709, real: 79500\n",
      "gbr: 264532.423, lasso: 307345.337, real: 320000\n",
      "gbr: 162218.542, lasso: 174579.577, real: 158000\n",
      "gbr: 133580.799, lasso: 148790.410, real: 140000\n",
      "gbr: 129477.076, lasso: 129238.540, real: 136500\n",
      "gbr: 134268.978, lasso: 153716.737, real: 107500\n",
      "gbr: 149520.603, lasso: 132796.684, real: 145000\n",
      "gbr: 207950.135, lasso: 252159.776, real: 200500\n",
      "gbr: 198420.912, lasso: 196980.952, real: 185000\n",
      "gbr: 93521.263, lasso: 88394.736, real: 105000\n",
      "gbr: 189680.800, lasso: 216640.112, real: 202665\n",
      "gbr: 175334.828, lasso: 157384.748, real: 186000\n",
      "gbr: 141037.401, lasso: 139384.535, real: 136000\n",
      "gbr: 192986.741, lasso: 181564.508, real: 200500\n",
      "gbr: 193291.840, lasso: 183527.657, real: 190000\n",
      "gbr: 187384.717, lasso: 164351.548, real: 187500\n",
      "gbr: 223582.682, lasso: 220968.145, real: 200000\n",
      "gbr: 203481.937, lasso: 227879.106, real: 172500\n",
      "gbr: 148711.825, lasso: 147270.333, real: 157000\n",
      "gbr: 206966.210, lasso: 219103.061, real: 213000\n",
      "gbr: 198907.463, lasso: 174625.531, real: 185000\n",
      "gbr: 117157.531, lasso: 99241.052, real: 124500\n",
      "gbr: 147597.628, lasso: 141307.636, real: 162900\n",
      "gbr: 242289.039, lasso: 249622.634, real: 260000\n",
      "gbr: 214707.284, lasso: 215632.374, real: 198500\n",
      "gbr: 118579.209, lasso: 103791.062, real: 120000\n",
      "gbr: 152280.655, lasso: 158593.991, real: 159500\n",
      "gbr: 116476.831, lasso: 107836.694, real: 105900\n",
      "gbr: 254954.696, lasso: 266026.952, real: 260000\n",
      "gbr: 155959.207, lasso: 148076.806, real: 143000\n",
      "gbr: 99029.314, lasso: 76643.936, real: 106500\n",
      "gbr: 177331.747, lasso: 187379.848, real: 178900\n",
      "gbr: 125383.629, lasso: 139290.152, real: 127000\n",
      "gbr: 105286.579, lasso: 114633.263, real: 90350\n",
      "gbr: 122756.424, lasso: 101371.528, real: 118500\n",
      "gbr: 196101.682, lasso: 189224.611, real: 190000\n",
      "gbr: 134802.419, lasso: 128112.425, real: 119900\n",
      "gbr: 171502.556, lasso: 187930.669, real: 183900\n",
      "gbr: 160082.981, lasso: 168377.961, real: 155000\n",
      "gbr: 429880.843, lasso: 385302.641, real: 386250\n",
      "gbr: 122411.137, lasso: 102797.737, real: 133000\n",
      "gbr: 205984.430, lasso: 236676.817, real: 193500\n",
      "gbr: 268858.175, lasso: 260887.868, real: 270000\n",
      "gbr: 160789.807, lasso: 164257.318, real: 141000\n",
      "gbr: 171665.956, lasso: 160918.465, real: 146000\n",
      "gbr: 127873.600, lasso: 120572.815, real: 128500\n",
      "gbr: 198237.980, lasso: 188982.891, real: 176000\n",
      "gbr: 222527.992, lasso: 235589.344, real: 214000\n",
      "gbr: 230807.196, lasso: 264494.908, real: 222000\n",
      "gbr: 379876.637, lasso: 354032.697, real: 415298\n",
      "gbr: 192266.552, lasso: 216630.354, real: 187750\n",
      "gbr: 200667.349, lasso: 217780.752, real: 199900\n",
      "gbr: 162458.481, lasso: 172061.544, real: 180000\n",
      "gbr: 225877.830, lasso: 214770.231, real: 206300\n",
      "gbr: 202008.361, lasso: 200712.338, real: 194000\n",
      "gbr: 131705.907, lasso: 145585.478, real: 142953\n",
      "gbr: 177939.437, lasso: 206085.995, real: 182900\n",
      "gbr: 98788.753, lasso: 67828.392, real: 116050\n",
      "gbr: 235273.823, lasso: 213778.054, real: 213250\n",
      "gbr: 145009.513, lasso: 146145.571, real: 139500\n",
      "gbr: 189573.632, lasso: 166686.299, real: 179000\n",
      "gbr: 110773.383, lasso: 86354.697, real: 107900\n",
      "gbr: 168916.562, lasso: 179596.268, real: 175900\n",
      "gbr: 155699.255, lasso: 170786.651, real: 158500\n",
      "gbr: 138085.064, lasso: 137555.050, real: 145000\n",
      "gbr: 229125.699, lasso: 248175.544, real: 217000\n",
      "gbr: 151348.230, lasso: 156552.261, real: 150500\n",
      "gbr: 152460.296, lasso: 130165.858, real: 108959\n",
      "gbr: 184574.660, lasso: 171028.277, real: 165600\n",
      "gbr: 223665.682, lasso: 216861.288, real: 201000\n",
      "gbr: 144097.519, lasso: 150226.186, real: 145500\n",
      "gbr: 294282.230, lasso: 288184.744, real: 319900\n",
      "gbr: 239374.393, lasso: 239280.437, real: 215000\n",
      "gbr: 152651.243, lasso: 175291.697, real: 180500\n",
      "gbr: 392984.679, lasso: 364171.537, real: 367294\n",
      "gbr: 267174.346, lasso: 261882.408, real: 239000\n",
      "gbr: 147157.914, lasso: 174257.338, real: 145900\n",
      "gbr: 183423.657, lasso: 173147.646, real: 161000\n",
      "gbr: 288508.363, lasso: 280030.591, real: 250000\n",
      "gbr: 120889.878, lasso: 127803.250, real: 89471\n",
      "gbr: 218309.785, lasso: 212067.889, real: 230000\n",
      "gbr: 110748.672, lasso: 137718.997, real: 147000\n",
      "gbr: 170257.159, lasso: 167634.562, real: 163900\n",
      "gbr: 124086.808, lasso: 103005.714, real: 97000\n",
      "gbr: 135500.471, lasso: 128719.212, real: 142000\n",
      "gbr: 189557.171, lasso: 212623.333, real: 197000\n",
      "gbr: 125075.339, lasso: 116484.582, real: 129000\n",
      "gbr: 241337.516, lasso: 223879.402, real: 232000\n",
      "gbr: 126444.438, lasso: 109288.102, real: 115000\n",
      "gbr: 168106.450, lasso: 154948.556, real: 175000\n",
      "gbr: 272172.769, lasso: 287761.342, real: 265000\n",
      "gbr: 199581.554, lasso: 219321.519, real: 207000\n",
      "gbr: 166024.508, lasso: 150715.889, real: 181000\n",
      "gbr: 188552.755, lasso: 206993.499, real: 176000\n",
      "gbr: 162587.668, lasso: 166950.931, real: 171000\n",
      "gbr: 173820.426, lasso: 210497.950, real: 196000\n",
      "gbr: 170180.000, lasso: 179387.935, real: 176000\n",
      "gbr: 119090.171, lasso: 101051.470, real: 113000\n",
      "gbr: 115950.961, lasso: 126257.829, real: 139000\n",
      "gbr: 136663.065, lasso: 124795.421, real: 135000\n",
      "gbr: 223199.406, lasso: 252566.110, real: 240000\n",
      "gbr: 110659.501, lasso: 100752.950, real: 112000\n",
      "gbr: 135184.524, lasso: 134143.563, real: 134000\n",
      "gbr: 277142.086, lasso: 289250.723, real: 316600\n",
      "gbr: 208290.954, lasso: 199255.648, real: 170000\n",
      "gbr: 108023.046, lasso: 113900.108, real: 116000\n",
      "gbr: 306537.948, lasso: 270051.568, real: 306000\n",
      "gbr: 111099.184, lasso: 88975.881, real: 82500\n",
      "gbr: 171156.907, lasso: 208091.620, real: 175000\n",
      "gbr: 100269.481, lasso: 108073.236, real: 106000\n",
      "gbr: 200978.332, lasso: 227383.737, real: 194000\n",
      "gbr: 209721.016, lasso: 235113.030, real: 194201\n",
      "gbr: 139154.600, lasso: 163874.295, real: 155900\n",
      "gbr: 144871.190, lasso: 127165.306, real: 138000\n",
      "gbr: 170542.114, lasso: 198552.304, real: 177000\n",
      "gbr: 201974.550, lasso: 200583.088, real: 214000\n",
      "gbr: 131045.861, lasso: 137778.773, real: 148000\n",
      "gbr: 114375.367, lasso: 110287.260, real: 127000\n",
      "gbr: 146840.093, lasso: 152152.421, real: 142500\n",
      "gbr: 84151.994, lasso: 73078.450, real: 80000\n",
      "gbr: 145108.969, lasso: 146991.338, real: 145000\n",
      "gbr: 167644.978, lasso: 183130.454, real: 171000\n",
      "gbr: 118912.030, lasso: 127592.852, real: 122500\n",
      "gbr: 129954.114, lasso: 119578.532, real: 139000\n",
      "gbr: 197735.856, lasso: 234726.124, real: 189000\n",
      "gbr: 115213.271, lasso: 121574.989, real: 120500\n",
      "gbr: 117254.267, lasso: 125686.980, real: 124000\n",
      "gbr: 148060.630, lasso: 149196.954, real: 160000\n",
      "gbr: 167432.752, lasso: 226078.814, real: 200000\n",
      "gbr: 150749.640, lasso: 167948.636, real: 160000\n",
      "gbr: 322513.789, lasso: 291940.359, real: 313000\n",
      "gbr: 268863.063, lasso: 256302.762, real: 275000\n",
      "gbr: 58193.704, lasso: 53619.084, real: 67000\n",
      "gbr: 154561.129, lasso: 137256.084, real: 159000\n",
      "gbr: 261145.704, lasso: 276807.929, real: 251000\n",
      "gbr: 89996.653, lasso: 75441.456, real: 92900\n",
      "gbr: 94439.716, lasso: 106450.972, real: 109500\n",
      "gbr: 409800.218, lasso: 339673.108, real: 385000\n",
      "gbr: 194241.507, lasso: 194430.427, real: 129000\n",
      "gbr: 183473.412, lasso: 191997.894, real: 82500\n",
      "gbr: 289092.844, lasso: 306396.852, real: 301000\n",
      "gbr: 248733.336, lasso: 237205.767, real: 249700\n",
      "gbr: 78717.315, lasso: 94357.663, real: 81000\n",
      "gbr: 207513.775, lasso: 209521.754, real: 187500\n",
      "gbr: 132525.876, lasso: 139393.716, real: 110000\n",
      "gbr: 145560.526, lasso: 141858.188, real: 117000\n",
      "gbr: 122744.150, lasso: 112023.248, real: 128500\n",
      "gbr: 199198.099, lasso: 210756.421, real: 213490\n",
      "gbr: 274234.143, lasso: 269459.896, real: 284000\n",
      "gbr: 233454.995, lasso: 236736.930, real: 230500\n",
      "gbr: 211863.616, lasso: 225812.585, real: 190000\n",
      "gbr: 132398.333, lasso: 120042.204, real: 135000\n",
      "gbr: 169568.294, lasso: 165895.916, real: 152000\n",
      "gbr: 83400.168, lasso: 66765.642, real: 87500\n",
      "gbr: 167377.170, lasso: 171884.369, real: 155000\n",
      "gbr: 97932.775, lasso: 95798.845, real: 115000\n",
      "gbr: 142643.271, lasso: 135036.436, real: 144000\n",
      "gbr: 249102.388, lasso: 231768.954, real: 248000\n",
      "gbr: 126817.978, lasso: 129937.051, real: 132500\n",
      "gbr: 136247.261, lasso: 145222.562, real: 136000\n",
      "gbr: 118825.226, lasso: 113239.607, real: 117000\n",
      "gbr: 92336.839, lasso: 70138.309, real: 82000\n",
      "gbr: 159506.433, lasso: 178476.940, real: 157500\n",
      "gbr: 107083.798, lasso: 112547.510, real: 110000\n",
      "gbr: 199682.619, lasso: 156723.523, real: 181000\n",
      "gbr: 198691.336, lasso: 212592.781, real: 192500\n",
      "gbr: 213720.069, lasso: 225318.900, real: 223500\n",
      "gbr: 177690.900, lasso: 181005.872, real: 181500\n",
      "gbr: 173253.070, lasso: 192829.164, real: 170000\n",
      "gbr: 202719.571, lasso: 240271.422, real: 187500\n",
      "gbr: 195685.292, lasso: 194500.053, real: 185900\n",
      "gbr: 140622.848, lasso: 150242.094, real: 160000\n",
      "gbr: 205329.480, lasso: 210389.240, real: 192000\n",
      "gbr: 180102.535, lasso: 187329.416, real: 181900\n",
      "gbr: 266269.082, lasso: 280254.503, real: 266000\n",
      "gbr: 86109.863, lasso: 82061.470, real: 99900\n",
      "gbr: 455290.060, lasso: 429686.475, real: 438780\n",
      "gbr: 249476.813, lasso: 242316.468, real: 229456\n",
      "gbr: 210632.471, lasso: 222912.000, real: 216837\n",
      "gbr: 91202.705, lasso: 120704.077, real: 110500\n",
      "gbr: 222668.085, lasso: 229745.596, real: 175900\n",
      "gbr: 428018.763, lasso: 448878.812, real: 538000\n",
      "gbr: 273917.596, lasso: 756619.630, real: 160000\n",
      "gbr: 199514.002, lasso: 216851.400, real: 172500\n",
      "gbr: 122750.241, lasso: 104859.545, real: 108000\n",
      "gbr: 134086.803, lasso: 151062.463, real: 131500\n",
      "gbr: 96012.234, lasso: 94236.737, real: 106250\n",
      "gbr: 384184.259, lasso: 408160.691, real: 385000\n",
      "gbr: 379395.256, lasso: 321537.247, real: 370878\n",
      "gbr: 359641.336, lasso: 333778.917, real: 345000\n",
      "gbr: 68739.647, lasso: 30125.783, real: 68500\n",
      "gbr: 232798.024, lasso: 256445.902, real: 250000\n",
      "gbr: 263165.925, lasso: 241107.600, real: 245350\n",
      "gbr: 142888.395, lasso: 135826.626, real: 125000\n",
      "gbr: 234447.653, lasso: 244372.761, real: 234000\n",
      "gbr: 133070.381, lasso: 118835.992, real: 145000\n",
      "gbr: 186213.059, lasso: 168601.933, real: 181000\n",
      "gbr: 137994.623, lasso: 154700.202, real: 104000\n",
      "gbr: 229424.400, lasso: 230218.385, real: 233000\n",
      "gbr: 219243.543, lasso: 230486.114, real: 164000\n",
      "gbr: 186406.410, lasso: 190280.920, real: 219500\n",
      "gbr: 222666.239, lasso: 212178.767, real: 195000\n",
      "gbr: 104151.763, lasso: 102753.596, real: 108000\n",
      "gbr: 133358.687, lasso: 123137.162, real: 149900\n",
      "gbr: 345469.532, lasso: 323167.595, real: 315000\n",
      "gbr: 172178.185, lasso: 178844.626, real: 177500\n",
      "gbr: 139463.183, lasso: 129476.152, real: 140000\n",
      "gbr: 194728.654, lasso: 226449.339, real: 193879\n",
      "gbr: 131766.800, lasso: 171823.730, real: 137900\n",
      "gbr: 117167.395, lasso: 131990.237, real: 118000\n",
      "gbr: 284452.378, lasso: 278861.830, real: 324000\n",
      "gbr: 486403.282, lasso: 398394.453, real: 555000\n",
      "gbr: 188004.464, lasso: 200106.200, real: 136000\n",
      "gbr: 80771.762, lasso: 58936.590, real: 82500\n",
      "gbr: 96389.356, lasso: 88800.913, real: 101000\n",
      "gbr: 317468.776, lasso: 327185.569, real: 314813\n",
      "gbr: 100550.112, lasso: 76569.544, real: 109500\n",
      "gbr: 142450.116, lasso: 144163.147, real: 163500\n",
      "gbr: 284723.546, lasso: 263009.152, real: 271000\n",
      "gbr: 221745.155, lasso: 234290.145, real: 205000\n",
      "gbr: 187292.854, lasso: 176955.463, real: 185000\n",
      "gbr: 141327.620, lasso: 144859.821, real: 160000\n",
      "gbr: 165449.539, lasso: 179288.741, real: 155000\n",
      "gbr: 93902.753, lasso: 99607.531, real: 91000\n",
      "gbr: 128323.386, lasso: 134303.464, real: 131000\n",
      "gbr: 177550.398, lasso: 198724.763, real: 165400\n",
      "gbr: 166057.145, lasso: 199347.809, real: 194700\n",
      "gbr: 164281.377, lasso: 161184.772, real: 155000\n",
      "gbr: 144402.907, lasso: 143998.267, real: 140000\n",
      "gbr: 143589.515, lasso: 148857.640, real: 147000\n",
      "gbr: 201599.367, lasso: 188912.371, real: 194000\n",
      "gbr: 175916.792, lasso: 217509.182, real: 179540\n",
      "gbr: 184161.357, lasso: 176909.673, real: 173000\n",
      "gbr: 102222.525, lasso: 100264.490, real: 109500\n",
      "gbr: 168256.984, lasso: 193330.414, real: 173733\n",
      "gbr: 141487.046, lasso: 142900.549, real: 129900\n",
      "gbr: 120261.761, lasso: 129522.838, real: 119000\n",
      "gbr: 124533.386, lasso: 122226.001, real: 125500\n",
      "gbr: 141916.278, lasso: 165145.162, real: 149300\n",
      "gbr: 301920.931, lasso: 298980.304, real: 305000\n",
      "gbr: 124606.156, lasso: 112583.582, real: 102000\n",
      "gbr: 175721.816, lasso: 183301.584, real: 178740\n",
      "gbr: 178229.634, lasso: 170756.547, real: 129500\n",
      "gbr: 107967.048, lasso: 100344.567, real: 79900\n",
      "gbr: 259490.027, lasso: 280475.290, real: 278000\n",
      "gbr: 111119.926, lasso: 124270.480, real: 118400\n",
      "gbr: 240975.401, lasso: 244951.381, real: 197000\n",
      "gbr: 146903.876, lasso: 163848.040, real: 140000\n",
      "gbr: 234087.086, lasso: 226500.333, real: 226000\n",
      "gbr: 123274.776, lasso: 125744.788, real: 132500\n",
      "gbr: 369834.410, lasso: 338821.127, real: 315000\n",
      "gbr: 213229.141, lasso: 232257.702, real: 224000\n",
      "gbr: 137729.603, lasso: 156023.726, real: 132500\n",
      "gbr: 121937.701, lasso: 107505.643, real: 119500\n",
      "gbr: 232888.369, lasso: 232328.463, real: 215000\n",
      "gbr: 164181.244, lasso: 180364.694, real: 210000\n",
      "gbr: 194630.371, lasso: 221513.593, real: 200141\n",
      "gbr: 151550.610, lasso: 172794.345, real: 185000\n",
      "gbr: 147661.808, lasso: 134024.298, real: 149900\n",
      "gbr: 124116.004, lasso: 103486.005, real: 129000\n",
      "gbr: 208293.199, lasso: 194021.954, real: 184100\n",
      "gbr: 140989.428, lasso: 146738.442, real: 135000\n",
      "gbr: 123668.076, lasso: 115172.571, real: 128000\n",
      "gbr: 358868.624, lasso: 331068.498, real: 374000\n",
      "gbr: 166010.421, lasso: 155851.411, real: 164000\n",
      "gbr: 170655.128, lasso: 169823.680, real: 157000\n",
      "gbr: 221572.031, lasso: 222164.438, real: 215000\n",
      "gbr: 164560.222, lasso: 174243.954, real: 165000\n",
      "gbr: 135070.556, lasso: 125495.833, real: 144000\n",
      "gbr: 106478.758, lasso: 118368.613, real: 125500\n",
      "gbr: 91755.000, lasso: 71358.022, real: 98300\n",
      "gbr: 93858.790, lasso: 79233.692, real: 91300\n",
      "gbr: 130711.614, lasso: 141926.076, real: 135960\n",
      "gbr: 217402.745, lasso: 208500.345, real: 226700\n",
      "gbr: 351806.190, lasso: 306855.889, real: 333168\n",
      "gbr: 112227.551, lasso: 86729.859, real: 114500\n",
      "gbr: 86687.231, lasso: 91498.060, real: 97000\n",
      "gbr: 158079.873, lasso: 162196.678, real: 181000\n",
      "gbr: 427158.496, lasso: 376809.253, real: 465000\n",
      "gbr: 312949.650, lasso: 300315.221, real: 290000\n",
      "gbr: 154754.260, lasso: 157852.014, real: 175000\n",
      "gbr: 312823.089, lasso: 299031.854, real: 235000\n",
      "gbr: 259776.451, lasso: 331369.529, real: 277000\n",
      "gbr: 370888.604, lasso: 309325.209, real: 325000\n",
      "gbr: 180258.319, lasso: 182377.052, real: 178000\n",
      "gbr: 234159.576, lasso: 240991.311, real: 235000\n",
      "gbr: 252503.418, lasso: 266741.893, real: 239000\n",
      "gbr: 94777.117, lasso: 80555.070, real: 85000\n",
      "0.09166708845892194\n"
     ]
    }
   ],
   "source": [
    "lasso_predict_all = lasso.predict(X_test[X_test.columns[mask_rfecv]])\n",
    "avg_score = 0\n",
    "for t, lp, gbrp in zip(result['SalePrice'], lasso_predict_all, result['Prediction']):\n",
    "    print(\"gbr: {:.3f}, lasso: {:.3f}, real: {}\".format(gbrp, lp, t))\n",
    "    mean_pred = (lp + gbrp)/2.0\n",
    "    score = sqrt(mean_squared_log_error([t], [mean_pred]))\n",
    "    avg_score += score\n",
    "avg_score = avg_score/float(len(lasso_predict_all))\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Combining both models actually allows to improve the score. The best combination on the Kaggle test set is 20% lasso and 80% gbr : using the features selected previously and this averaging of models we get a score of 0.12916 (achieved without subsampling in gbr to reduce randomness of results)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's, for fun, see what happens if we add an SVM on top. SVMs are known to be sensitive to the scaling of the data, so we should apply a scaler, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearSVC\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
