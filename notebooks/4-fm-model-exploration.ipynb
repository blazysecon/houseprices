{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are facing a regression problem. Since interactions between features are to be expected, a decision-tree based approach seems appropriate, but let's also try a Lasso regression and SVR to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the \"autoreload\" extension\n",
    "%load_ext autoreload\n",
    "\n",
    "# always reload modules marked with \"%aimport\"\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.join(os.getcwd(), os.pardir, 'src')\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# import my method from the source code\n",
    "%aimport features.build_features\n",
    "%aimport visualization.visualize\n",
    "from features.build_features import read_raw_data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# features selected by RFECV in 3-fm-feature-reduction \n",
    "\n",
    "features = ['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
    "       'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'BsmtQual', 'BsmtCond',\n",
    "       'BsmtExposure', 'BsmtUnfSF', '1stFlrSF', '2ndFlrSF', 'GrLivArea',\n",
    "       'BsmtFullBath', 'KitchenAbvGr', 'KitchenQual', 'FireplaceQu',\n",
    "       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "       'ScreenPorch', 'PoolArea', 'MoSold', 'MSSubClass_60',\n",
    "       'MSZoning_C (all)', 'LotConfig_CulDSac', 'Neighborhood_ClearCr',\n",
    "       'Neighborhood_Crawfor', 'Neighborhood_OldTown', 'Neighborhood_StoneBr',\n",
    "       'Condition1_Artery', 'Condition1_Norm', 'Exterior1st_BrkFace',\n",
    "       'BsmtFinType1_GLQ', 'Functional_Typ', 'GarageType_Attchd',\n",
    "       'SaleType_New', 'SaleCondition_Abnorml', 'SaleCondition_Family',\n",
    "       'BsmtFinSF']\n",
    "\n",
    "fid = features + ['Id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.22567824583081775, 0.21553487753850015, 0.21058137245633135, 0.18247887895216577, 0.19169848844497978, 0.19677458508357587, 0.17090873525538192, 0.18797073238340353, 0.18185491116691205, 0.23037204141204656]\n",
      "Lasso: 0.19938528685241147\n",
      "\n",
      "[0.1565447739716441, 0.15492588629000068, 0.15451953233726023, 0.15158406010047398, 0.1453904136927294, 0.14950359155857088, 0.1540218229360688, 0.15108365154117273, 0.15045649961723584, 0.14257484285861594]\n",
      "SVR: 0.15106050749037725\n",
      "\n",
      "[0.13634252999333954, 0.1366370958085369, 0.14997087184780028, 0.14223500492996774, 0.14363685282383046, 0.14258143739142887, 0.1306995758863363, 0.13384319761885227, 0.13347759284265323, 0.13814968693116458]\n",
      "GBR: 0.138757384607391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "df = read_raw_data(\"../data/intermediate/eval.csv\")\n",
    "\n",
    "X_w_id = df[fid]\n",
    "X = df[features]\n",
    "y = df['SalePrice'] \n",
    "\n",
    "# use log transform to ensure positive predictions with lasso!\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "\n",
    "pipe = make_pipeline(Lasso(max_iter=50000))\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(pipe, X, y_log, cv=shuffle_split, scoring='neg_mean_squared_error')\n",
    "scores = [sqrt(abs(s)) for s in scores]\n",
    "print(scores)\n",
    "print(\"Lasso: {}\\n\".format(np.mean(scores)))\n",
    "\n",
    "pipe = make_pipeline(MinMaxScaler(), SVR(C=1000))\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(pipe, X, y_log, cv=shuffle_split, scoring='neg_mean_squared_error')\n",
    "scores = [sqrt(abs(s)) for s in scores]\n",
    "print(scores)\n",
    "print(\"SVR: {}\\n\".format(np.mean(scores)))\n",
    "\n",
    "pipe = make_pipeline(GradientBoostingRegressor())\n",
    "shuffle_split = ShuffleSplit(test_size=.5, train_size=.5, n_splits=10)\n",
    "scores = cross_val_score(pipe, X, y, cv=shuffle_split, scoring='neg_mean_squared_log_error')\n",
    "scores = [sqrt(abs(s)) for s in scores]\n",
    "print(scores)\n",
    "print(\"GBR: {}\\n\".format(np.mean(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient boosting regressor with default parameters already achieves the best results. The parameters for the SVR and Lasso have been fixed by hand with trial and error. A more rigorous approach would of course be recommended. Nevertheless let's continue with the gradient boosting tree since it produces the best results.\n",
    "\n",
    "What parameters should be selected for the GBR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   17.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross_validaton score : 0.138\n",
      "Test set score : 0.135\n",
      "Best parameters : {'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_w_id, y)\n",
    "\n",
    "param_grid = {'max_depth' : [3, 4, 5],\n",
    "              'learning_rate' : [0.01, 0.1],\n",
    "              'min_samples_leaf' : [1, 2]}\n",
    "\n",
    "gridcv = GridSearchCV(GradientBoostingRegressor(), param_grid=param_grid,    \n",
    "                            cv=5, scoring='neg_mean_squared_log_error', verbose=1)\n",
    "gridcv.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Best cross_validaton score : {:.3f}\".format(sqrt(abs(gridcv.best_score_))))\n",
    "print(\"Test set score : {:.3f}\".format(sqrt(abs(gridcv.score(X_test, y_test)))))\n",
    "print(\"Best parameters : {}\".format(gridcv.best_params_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maximum depth of 4 levels, the default learning rate and default number of leaf nodes produce the best results. Let's take a look at the predictions the GBR makes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth: 149700, predict.: 156789.53464498225, score: 0.04627076887967796\n",
      "truth: 139000, predict.: 112359.17034869747, score: 0.21277160901718162\n",
      "truth: 140000, predict.: 132809.89428047783, score: 0.05272329651874763\n",
      "truth: 76500, predict.: 89243.10610740425, score: 0.15407156782438847\n",
      "truth: 212000, predict.: 220446.53052078566, score: 0.039068718106829436\n",
      "truth: 68400, predict.: 74000.6453792225, score: 0.0786998834066619\n",
      "truth: 224900, predict.: 206486.75702517046, score: 0.08541918274623583\n",
      "truth: 116000, predict.: 107719.26453266211, score: 0.07406108807523637\n",
      "truth: 188000, predict.: 145113.63152845812, score: 0.2589232896086848\n",
      "truth: 129000, predict.: 181507.9099374158, score: 0.34148458679466565\n",
      "truth: 208900, predict.: 214085.87471989953, score: 0.024521433748315502\n",
      "truth: 181000, predict.: 175486.5946241146, score: 0.03093420160736926\n",
      "truth: 187100, predict.: 195462.3082392804, score: 0.04372410216931044\n",
      "truth: 250000, predict.: 222262.37877315463, score: 0.1176018483174186\n",
      "truth: 446261, predict.: 410587.80516087654, score: 0.08331398386172673\n",
      "truth: 179900, predict.: 175785.7204776065, score: 0.02313525485680934\n",
      "truth: 114500, predict.: 119671.72700155474, score: 0.044177185424253196\n",
      "truth: 189000, predict.: 154224.7135053528, score: 0.20333510457363246\n",
      "truth: 106500, predict.: 110703.78122468744, score: 0.038712654833387816\n",
      "truth: 161000, predict.: 143436.7821465318, score: 0.11550920885772342\n",
      "truth: 80000, predict.: 101329.60065179146, score: 0.2363493105266734\n",
      "truth: 129500, predict.: 125441.2465912808, score: 0.031843136987635745\n",
      "truth: 85000, predict.: 96293.63866266057, score: 0.12474962284233371\n",
      "truth: 165000, predict.: 167731.1095042259, score: 0.01641658592476425\n",
      "truth: 79000, predict.: 84912.04371615798, score: 0.07216720713442903\n",
      "truth: 116000, predict.: 110707.33885805248, score: 0.04669964644362423\n",
      "truth: 179000, predict.: 175370.88220991875, score: 0.02048263200066458\n",
      "truth: 195000, predict.: 219105.99380313014, score: 0.11655547993473725\n",
      "truth: 124500, predict.: 124761.33018728218, score: 0.0020968209229490498\n",
      "truth: 75000, predict.: 83719.52463594866, score: 0.10998271733197917\n",
      "truth: 200000, predict.: 226773.54314757916, score: 0.1256339554008985\n",
      "truth: 133000, predict.: 153995.9479402436, score: 0.14657613665691116\n",
      "truth: 132000, predict.: 121679.43095110402, score: 0.08141130869474544\n",
      "truth: 109500, predict.: 103631.80744637476, score: 0.05507972774744552\n",
      "truth: 360000, predict.: 369842.55493230314, score: 0.026973282491418615\n",
      "truth: 172000, predict.: 147231.50574639597, score: 0.15548728175247994\n",
      "truth: 394432, predict.: 388552.0869541778, score: 0.015019484198624866\n",
      "truth: 154000, predict.: 153751.945913419, score: 0.001612028983489111\n",
      "truth: 105000, predict.: 106318.40202082774, score: 0.012477916133653011\n",
      "truth: 135000, predict.: 169959.73863221327, score: 0.23028527533670662\n",
      "truth: 110000, predict.: 136862.23410915397, score: 0.21849267936937267\n",
      "truth: 94500, predict.: 95461.07610004385, score: 0.010118643263711036\n",
      "truth: 130250, predict.: 133927.22967696562, score: 0.027840698893484728\n",
      "truth: 125500, predict.: 114645.93595326053, score: 0.09045644294312005\n",
      "truth: 170000, predict.: 164516.27646704295, score: 0.0327887305793606\n",
      "truth: 144152, predict.: 145229.72863013195, score: 0.007448474162019991\n",
      "truth: 172500, predict.: 190114.35375302055, score: 0.09722797939449279\n",
      "truth: 240000, predict.: 267253.4754513992, score: 0.10755820607515254\n",
      "truth: 150000, predict.: 142831.94323965433, score: 0.048966242485644074\n",
      "truth: 402000, predict.: 361787.1858281659, score: 0.1053956576246815\n",
      "truth: 403000, predict.: 325838.29237749183, score: 0.21253475168243163\n",
      "truth: 237000, predict.: 261248.69080835494, score: 0.09741225923411889\n",
      "truth: 137500, predict.: 117320.92102975544, score: 0.1587095715588589\n",
      "truth: 130000, predict.: 139484.41030761617, score: 0.07041786744978751\n",
      "truth: 224900, predict.: 203059.25431855457, score: 0.10215755107313917\n",
      "truth: 178000, predict.: 179753.96306343828, score: 0.009805438889310736\n",
      "truth: 148000, predict.: 148156.1643718326, score: 0.0010546012576586605\n",
      "truth: 223000, predict.: 232644.8161346315, score: 0.042340938856359145\n",
      "truth: 124900, predict.: 120854.23063869246, score: 0.032928035217343776\n",
      "truth: 132000, predict.: 129015.87439178544, score: 0.02286629326971301\n",
      "truth: 140000, predict.: 141945.1733444016, score: 0.013798359343642375\n",
      "truth: 119000, predict.: 117183.66755748332, score: 0.015380850741081531\n",
      "truth: 201000, predict.: 200785.31291869617, score: 0.0010686604321872295\n",
      "truth: 202665, predict.: 189519.1026059177, score: 0.06706420256968926\n",
      "truth: 147500, predict.: 152689.57592121625, score: 0.03457853860362903\n",
      "truth: 255000, predict.: 246124.70082529885, score: 0.03542508232766828\n",
      "truth: 81000, predict.: 83207.78227313848, score: 0.026891398148787715\n",
      "truth: 106250, predict.: 105008.38706223713, score: 0.011754472770679314\n",
      "truth: 161500, predict.: 164607.23530231626, score: 0.01905698461073868\n",
      "truth: 130000, predict.: 123257.43799786842, score: 0.05325886969698779\n",
      "truth: 179900, predict.: 198643.56776744136, score: 0.09911043655539409\n",
      "truth: 242000, predict.: 286032.1412553786, score: 0.16716582424221116\n",
      "truth: 139000, predict.: 134817.69966356622, score: 0.03055021695234572\n",
      "truth: 170000, predict.: 188143.5258623207, score: 0.10140610269040451\n",
      "truth: 141000, predict.: 136408.42856425053, score: 0.033106115159879934\n",
      "truth: 134000, predict.: 134537.76742374548, score: 0.004005128534723568\n",
      "truth: 136000, predict.: 131492.0441592875, score: 0.033708284558516155\n",
      "truth: 227000, predict.: 208392.40411571163, score: 0.08552676349625443\n",
      "truth: 155000, predict.: 136148.13474192304, score: 0.12968070459411507\n",
      "truth: 136000, predict.: 137908.65607280633, score: 0.013936565980474214\n",
      "truth: 270000, predict.: 258350.98839502886, score: 0.044102711475179746\n",
      "truth: 359100, predict.: 331674.65858682373, score: 0.07944612652775263\n",
      "truth: 108480, predict.: 99612.71845888368, score: 0.0852751518018362\n",
      "truth: 189950, predict.: 186086.26749900662, score: 0.02055040037826039\n",
      "truth: 170000, predict.: 162642.41968460215, score: 0.044244124188713485\n",
      "truth: 165000, predict.: 174486.59765280303, score: 0.05590213100544972\n",
      "truth: 113000, predict.: 129892.9177221135, score: 0.13932143157913934\n",
      "truth: 178900, predict.: 175329.61654618554, score: 0.020159151248156704\n",
      "truth: 185000, predict.: 189730.19971518812, score: 0.02524710166310129\n",
      "truth: 122000, predict.: 208101.42581704503, score: 0.5340011488883025\n",
      "truth: 118000, predict.: 114689.41265517034, score: 0.028456664631271167\n",
      "truth: 115000, predict.: 124883.33941171612, score: 0.0824472002782759\n",
      "truth: 133700, predict.: 125088.827541548, score: 0.0665738639607607\n",
      "truth: 112000, predict.: 111705.4004864038, score: 0.0026337947091210623\n",
      "truth: 64500, predict.: 108330.40632587876, score: 0.5185143781847916\n",
      "truth: 250000, predict.: 239523.12741426387, score: 0.04281076530791772\n",
      "truth: 127500, predict.: 128646.71411900541, score: 0.008953562648869706\n",
      "truth: 190000, predict.: 195775.97302488986, score: 0.029946783304366065\n",
      "truth: 120000, predict.: 137749.52922504285, score: 0.13794421386907274\n",
      "truth: 225000, predict.: 243167.03352468673, score: 0.07764785371473515\n",
      "truth: 187000, predict.: 181667.14140311195, score: 0.028932340656391276\n",
      "truth: 412500, predict.: 389132.2688498958, score: 0.058316751623047836\n",
      "truth: 184750, predict.: 428897.6733171544, score: 0.8422117257626596\n",
      "truth: 97500, predict.: 145573.6050949494, score: 0.4008260706322968\n",
      "truth: 192140, predict.: 176383.42758572276, score: 0.08556361682303582\n",
      "truth: 139000, predict.: 142996.62181766133, score: 0.028346872126473244\n",
      "truth: 169000, predict.: 180591.9676941239, score: 0.06634106958868458\n",
      "truth: 85000, predict.: 104217.41768420249, score: 0.20382584578058172\n",
      "truth: 111000, predict.: 114200.77304954731, score: 0.02842761264853344\n",
      "truth: 154300, predict.: 161402.02113157904, score: 0.04499923371850478\n",
      "truth: 370878, predict.: 341731.51890398737, score: 0.08184754126950722\n",
      "truth: 374000, predict.: 344093.15918328264, score: 0.08334313273238436\n",
      "truth: 132000, predict.: 141980.08547915184, score: 0.07288434956294587\n",
      "truth: 255000, predict.: 266606.7152548747, score: 0.04451088004714698\n",
      "truth: 354000, predict.: 321389.27398739243, score: 0.09664354653880558\n",
      "truth: 130000, predict.: 119680.94384535437, score: 0.08270438661607393\n",
      "truth: 311872, predict.: 268464.6739395373, score: 0.14987299168397072\n",
      "truth: 129000, predict.: 123806.4417727095, score: 0.04109268657605192\n",
      "truth: 190000, predict.: 220361.84781782862, score: 0.14824616069546082\n",
      "truth: 174000, predict.: 188790.93202414262, score: 0.08158447355089926\n",
      "truth: 110000, predict.: 115121.07621890432, score: 0.04550364101432436\n",
      "truth: 268000, predict.: 250823.59540151723, score: 0.06623684010759945\n",
      "truth: 136500, predict.: 141619.1839907455, score: 0.03681677280344964\n",
      "truth: 185900, predict.: 194107.7528388867, score: 0.043204309690802134\n",
      "truth: 98000, predict.: 105010.69778307674, score: 0.06909406870990331\n",
      "truth: 402861, predict.: 421682.8840085567, score: 0.04566187175901604\n",
      "truth: 83500, predict.: 97013.47961669217, score: 0.15000163392895516\n",
      "truth: 210000, predict.: 168901.17564061092, score: 0.2177925876449862\n",
      "truth: 110000, predict.: 105367.1822674212, score: 0.043028742147331656\n",
      "truth: 239686, predict.: 272177.88762460026, score: 0.12712561970309721\n",
      "truth: 233000, predict.: 244118.09890748738, score: 0.046613471080734215\n",
      "truth: 210000, predict.: 217503.19942331844, score: 0.03510586542487282\n",
      "truth: 259500, predict.: 206372.25914686525, score: 0.22907408934604234\n",
      "truth: 224000, predict.: 224699.74354803507, score: 0.003118972125045971\n",
      "truth: 159434, predict.: 114738.3797021878, score: 0.32897302261108585\n",
      "truth: 239000, predict.: 194569.30331968374, score: 0.2056741816179226\n",
      "truth: 127000, predict.: 137878.94658449217, score: 0.08218839379947873\n",
      "truth: 73000, predict.: 94307.30850927737, score: 0.25609615327686264\n",
      "truth: 144000, predict.: 124918.84646928331, score: 0.14214794061452452\n",
      "truth: 239000, predict.: 227241.33451428436, score: 0.050450735044806905\n",
      "truth: 350000, predict.: 365023.1440127139, score: 0.042027487752614334\n",
      "truth: 294000, predict.: 264736.92070811935, score: 0.104842810529016\n",
      "truth: 160000, predict.: 146092.20932614506, score: 0.09093522716725033\n",
      "truth: 451950, predict.: 418471.968700218, score: 0.07696146995209752\n",
      "truth: 204000, predict.: 214136.43956666315, score: 0.04849315404611332\n",
      "truth: 177000, predict.: 165106.82630548716, score: 0.069556629047689\n",
      "truth: 173000, predict.: 174229.27180289265, score: 0.007080450629194601\n",
      "truth: 215000, predict.: 223520.2345558149, score: 0.03886373945917576\n",
      "truth: 187500, predict.: 185546.87250880175, score: 0.01047125715342112\n",
      "truth: 128000, predict.: 130416.31887172298, score: 0.01870137771798852\n",
      "truth: 127500, predict.: 123909.00751836752, score: 0.0285686514005441\n",
      "truth: 135000, predict.: 123183.41033613127, score: 0.0915996822052314\n",
      "truth: 177000, predict.: 177440.25238073434, score: 0.0024841993536934837\n",
      "truth: 142000, predict.: 140777.42260449563, score: 0.008646916397417215\n",
      "truth: 124000, predict.: 124929.87591385173, score: 0.007470961567618062\n",
      "truth: 200000, predict.: 203904.6019725976, score: 0.019334784785158377\n",
      "truth: 131000, predict.: 137076.69937412016, score: 0.04534295701647828\n",
      "truth: 174900, predict.: 152550.098716193, score: 0.13672048608943044\n",
      "truth: 100000, predict.: 95476.70942836785, score: 0.046287374822595595\n",
      "truth: 315000, predict.: 387003.32772661105, score: 0.2058600622995872\n",
      "truth: 123000, predict.: 125483.74958067665, score: 0.019991748481899663\n",
      "truth: 192000, predict.: 191177.52650055182, score: 0.004292895134922148\n",
      "truth: 143500, predict.: 144949.08914274178, score: 0.010047466540559213\n",
      "truth: 162900, predict.: 140099.8359239933, score: 0.1507802343756257\n",
      "truth: 194000, predict.: 204021.18712390694, score: 0.05036543465232235\n",
      "truth: 126000, predict.: 112498.39617033083, score: 0.11334198917268701\n",
      "truth: 156000, predict.: 143018.44120929917, score: 0.08688184395361809\n",
      "truth: 214000, predict.: 218243.89666677554, score: 0.019637123568093884\n",
      "truth: 140000, predict.: 147686.71275209184, score: 0.0534504300610017\n",
      "truth: 137000, predict.: 125788.8954064201, score: 0.08537520671472265\n",
      "truth: 185000, predict.: 194479.43118402726, score: 0.04997031664872864\n",
      "truth: 164990, predict.: 188492.57049011852, score: 0.13317297054223332\n",
      "truth: 289000, predict.: 241879.4379647656, score: 0.17798660224107365\n",
      "truth: 320000, predict.: 340192.37429679953, score: 0.06119008307727469\n",
      "truth: 136500, predict.: 154801.68297896153, score: 0.12581935230536168\n",
      "truth: 213250, predict.: 232172.82099253678, score: 0.08501644385835583\n",
      "truth: 157000, predict.: 158576.7661521513, score: 0.009992936422921872\n",
      "truth: 150500, predict.: 144475.2462750146, score: 0.040854620285477594\n",
      "truth: 144000, predict.: 137947.75004806285, score: 0.042938004279758246\n",
      "truth: 119500, predict.: 124925.59791561308, score: 0.0444016086105794\n",
      "truth: 250580, predict.: 201501.2383534027, score: 0.21798173177227298\n",
      "truth: 176485, predict.: 189314.55975396183, score: 0.07017369799358697\n",
      "truth: 163000, predict.: 154626.99198540192, score: 0.0527341552858136\n",
      "truth: 155000, predict.: 138511.05778029325, score: 0.1124741868879191\n",
      "truth: 134500, predict.: 135252.30104769493, score: 0.0055776904772386615\n",
      "truth: 203000, predict.: 218998.2018266864, score: 0.075857180044828\n",
      "truth: 155000, predict.: 140007.10789563393, score: 0.10173123403871642\n",
      "truth: 275000, predict.: 246836.86859030364, score: 0.10804301539044658\n",
      "truth: 132250, predict.: 151537.02002080277, score: 0.136134918551452\n",
      "truth: 143250, predict.: 127951.08372731494, score: 0.11294248841892163\n",
      "truth: 380000, predict.: 440294.5297696021, score: 0.14727227572200263\n",
      "truth: 179665, predict.: 213471.83338203563, score: 0.17241000880135182\n",
      "truth: 144500, predict.: 147445.80396531025, score: 0.02018103170322405\n",
      "truth: 190000, predict.: 186498.4075403996, score: 0.01860127295278602\n",
      "truth: 124500, predict.: 123519.48416869556, score: 0.007906741972718123\n",
      "truth: 285000, predict.: 300210.63209155283, score: 0.05199497722089852\n",
      "truth: 124000, predict.: 125692.81895002739, score: 0.013559311267711038\n",
      "truth: 131400, predict.: 142133.29499917352, score: 0.07851863373066159\n",
      "truth: 106000, predict.: 122602.13974353898, score: 0.1455041047980199\n",
      "truth: 132000, predict.: 133774.87971614313, score: 0.013356361948279272\n",
      "truth: 153900, predict.: 166660.56159255543, score: 0.07965564029077399\n",
      "truth: 424870, predict.: 386294.4065870038, score: 0.09518321462885737\n",
      "truth: 139000, predict.: 156058.77842293904, score: 0.11575800151849869\n",
      "truth: 194500, predict.: 218002.27166625203, score: 0.11407276588637494\n",
      "truth: 392500, predict.: 295529.6193312101, score: 0.28376663479367537\n",
      "truth: 110000, predict.: 148125.95460039077, score: 0.297580250756603\n",
      "truth: 87000, predict.: 113144.86534618883, score: 0.2627582172199787\n",
      "truth: 85000, predict.: 72348.93279263994, score: 0.16114849696990596\n",
      "truth: 136905, predict.: 137530.5883399929, score: 0.004559065158323605\n",
      "truth: 171750, predict.: 183267.37558125844, score: 0.06490585826088413\n",
      "truth: 120000, predict.: 127493.12476134214, score: 0.060570207152894184\n",
      "truth: 138500, predict.: 128637.22880730941, score: 0.07387350908196133\n",
      "truth: 339750, predict.: 295485.07246416534, score: 0.13959129273317572\n",
      "truth: 95000, predict.: 132350.20307386294, score: 0.3315716008642777\n",
      "truth: 160200, predict.: 166903.3991087873, score: 0.0409919112602708\n",
      "truth: 133000, predict.: 140434.88514238203, score: 0.05439440412532015\n",
      "truth: 165600, predict.: 188874.1509440349, score: 0.1315049391865557\n",
      "truth: 156000, predict.: 142850.12351960927, score: 0.08805942380903176\n",
      "truth: 226000, predict.: 204787.77687282342, score: 0.098560332803169\n",
      "truth: 120000, predict.: 126036.61570286714, score: 0.04908032364176229\n",
      "truth: 178000, predict.: 180101.19182409561, score: 0.011735253893421671\n",
      "truth: 140200, predict.: 130244.13352987758, score: 0.07365878984171914\n",
      "truth: 180500, predict.: 164433.8165190253, score: 0.09322207841098162\n",
      "truth: 157500, predict.: 150628.28957803556, score: 0.04461002508609013\n",
      "truth: 137500, predict.: 139222.28828682806, score: 0.012447845010751024\n",
      "truth: 237500, predict.: 206213.61308983827, score: 0.14125439639542314\n",
      "truth: 152000, predict.: 136927.73941125046, score: 0.10442645955180829\n",
      "truth: 143000, predict.: 152923.11743762466, score: 0.06709021065896259\n",
      "truth: 168000, predict.: 180878.34772493696, score: 0.07386029007628814\n",
      "truth: 180500, predict.: 161581.97999439007, score: 0.11071749920042429\n",
      "truth: 90000, predict.: 136622.83710311668, score: 0.41741065348424655\n",
      "truth: 142000, predict.: 136694.6135300459, score: 0.038077444910124214\n",
      "truth: 168500, predict.: 177623.56402316334, score: 0.052730447442321804\n",
      "truth: 276000, predict.: 332396.6996656578, score: 0.18592765367826303\n",
      "truth: 158500, predict.: 150703.01814489413, score: 0.050443133964364506\n",
      "truth: 192000, predict.: 193338.37360656308, score: 0.006946476829325476\n",
      "truth: 183000, predict.: 185946.73366873452, score: 0.01597401513643959\n",
      "truth: 228500, predict.: 275305.2943600443, score: 0.18634368883472163\n",
      "truth: 229456, predict.: 250274.45278227978, score: 0.08684647433159576\n",
      "truth: 118500, predict.: 123325.4574753004, score: 0.03991356585764727\n",
      "truth: 198900, predict.: 205484.90450847184, score: 0.03257022688478095\n",
      "truth: 167000, predict.: 151890.1859405609, score: 0.09483541791235339\n",
      "truth: 465000, predict.: 421494.6413009534, score: 0.09823011965724149\n",
      "truth: 324000, predict.: 308748.51989741303, score: 0.04821626925447653\n",
      "truth: 142500, predict.: 136631.0669646209, score: 0.04205734680182083\n",
      "truth: 205000, predict.: 238474.12005815812, score: 0.15125012929712867\n",
      "truth: 140000, predict.: 164866.29135466242, score: 0.16349129002080254\n",
      "truth: 149900, predict.: 158540.82651454298, score: 0.056043371985859736\n",
      "truth: 112000, predict.: 87882.93526140937, score: 0.2424907733696351\n",
      "truth: 236500, predict.: 242624.88081723577, score: 0.025568235594429112\n",
      "truth: 179540, predict.: 180014.27587154604, score: 0.002638119139840356\n",
      "truth: 97000, predict.: 114011.24488530702, score: 0.16158456617234762\n",
      "truth: 211000, predict.: 209075.82649184632, score: 0.009161097511411143\n",
      "truth: 284000, predict.: 263803.9912752619, score: 0.0737675984980104\n",
      "truth: 280000, predict.: 316261.31382584095, score: 0.12177880169096866\n",
      "truth: 277500, predict.: 286730.33555648813, score: 0.03272112750497769\n",
      "truth: 277000, predict.: 262089.99771209224, score: 0.05532935331768485\n",
      "truth: 228500, predict.: 238208.89308176897, score: 0.041611602035500184\n",
      "truth: 160000, predict.: 138720.71072254042, score: 0.14271022005986111\n",
      "truth: 80500, predict.: 73311.68006199795, score: 0.09353602420829787\n",
      "truth: 135750, predict.: 113388.7445757659, score: 0.17999137390514086\n",
      "truth: 82500, predict.: 86098.86905354224, score: 0.04269747608845087\n",
      "truth: 182900, predict.: 189288.53784266513, score: 0.03433276623407089\n",
      "truth: 186500, predict.: 172699.15381875358, score: 0.07687972517729591\n",
      "truth: 184000, predict.: 166866.57385489027, score: 0.09774066545662485\n",
      "truth: 118500, predict.: 129015.7153571481, score: 0.08502057302122878\n",
      "truth: 269790, predict.: 227965.66777819925, score: 0.1684481608624715\n",
      "truth: 175000, predict.: 199325.74677131427, score: 0.13015373359041682\n",
      "truth: 82500, predict.: 110891.32817565871, score: 0.29574929962712737\n",
      "truth: 113000, predict.: 107029.15287411897, score: 0.054286070905822825\n",
      "truth: 146800, predict.: 144975.1681054684, score: 0.012508557127301145\n",
      "truth: 130000, predict.: 126412.81488303165, score: 0.02798137203249773\n",
      "truth: 148000, predict.: 141027.84687184205, score: 0.04825457330153604\n",
      "truth: 328000, predict.: 273863.31972164783, score: 0.18038385691338732\n",
      "truth: 147000, predict.: 135362.0599271496, score: 0.08247888802949888\n",
      "truth: 183900, predict.: 162353.70350449655, score: 0.12461409981832716\n",
      "truth: 129500, predict.: 161422.25142542602, score: 0.22034120321882256\n",
      "truth: 260000, predict.: 321155.5973661291, score: 0.21124336927377385\n",
      "truth: 174500, predict.: 189966.13917324445, score: 0.08492063319775944\n",
      "truth: 88000, predict.: 110966.9559999041, score: 0.23189329689933658\n",
      "truth: 145000, predict.: 163961.88983253593, score: 0.12289948176123033\n",
      "truth: 145000, predict.: 131830.26450548886, score: 0.09521783328434807\n",
      "truth: 230000, predict.: 226486.49355506527, score: 0.015393929433633602\n",
      "truth: 171000, predict.: 166234.5160600095, score: 0.02826385014165922\n",
      "truth: 265900, predict.: 214828.28929532372, score: 0.21328034959169884\n",
      "truth: 149500, predict.: 156663.5081070687, score: 0.04680354612950843\n",
      "truth: 106000, predict.: 104663.17618916521, score: 0.012691625443812526\n",
      "truth: 52000, predict.: 92775.68339691588, score: 0.5789324025574505\n",
      "truth: 112000, predict.: 156587.0948703781, score: 0.3351109583010867\n",
      "truth: 175000, predict.: 164994.43929848587, score: 0.058873855289567345\n",
      "truth: 235000, predict.: 216694.51311058647, score: 0.08109656666120735\n",
      "truth: 175000, predict.: 152970.0297052787, score: 0.13454313306063703\n",
      "truth: 745000, predict.: 589645.9846785181, score: 0.23386153388558917\n",
      "truth: 161750, predict.: 146475.31239684008, score: 0.09919439048220902\n",
      "truth: 169990, predict.: 176869.78575998993, score: 0.03967394754936926\n",
      "truth: 302000, predict.: 270672.77259601554, score: 0.10951602404515803\n",
      "truth: 206000, predict.: 194701.97186343992, score: 0.0564058470769524\n",
      "truth: 187500, predict.: 219316.80794828307, score: 0.15673767699197505\n",
      "truth: 125000, predict.: 133660.05651585388, score: 0.0669854292842551\n",
      "truth: 255500, predict.: 267986.5186917927, score: 0.047714083850371125\n",
      "truth: 176000, predict.: 175968.95867654827, score: 0.0001763857089169818\n",
      "truth: 230000, predict.: 234347.42576617605, score: 0.01872535015881205\n",
      "truth: 146500, predict.: 152748.89122118108, score: 0.04176963154276514\n",
      "truth: 117000, predict.: 114541.91274982356, score: 0.02123294514814944\n",
      "truth: 109500, predict.: 116683.25666943706, score: 0.06353794426784809\n",
      "truth: 179900, predict.: 201087.01860922205, score: 0.11133601615104638\n",
      "truth: 107500, predict.: 126250.73345727983, score: 0.16077764856586718\n",
      "truth: 108000, predict.: 121361.10065835327, score: 0.11663815786391218\n",
      "truth: 140000, predict.: 129671.19787308133, score: 0.07663985428150966\n",
      "truth: 102776, predict.: 89683.0172069164, score: 0.13626901991619\n",
      "truth: 167240, predict.: 180971.79159387495, score: 0.07891081137921852\n",
      "truth: 226000, predict.: 249313.2332460352, score: 0.09817465770262501\n",
      "truth: 124000, predict.: 123249.32799610858, score: 0.006072155943357416\n",
      "truth: 90000, predict.: 95590.92918470722, score: 0.06026761235979805\n",
      "truth: 184000, predict.: 196304.9763614041, score: 0.06473335348241349\n",
      "truth: 135500, predict.: 130276.10776261361, score: 0.03931524036887524\n",
      "truth: 117500, predict.: 125482.80911620066, score: 0.06572989503661475\n",
      "truth: 193000, predict.: 182466.39246414724, score: 0.056123884609037944\n",
      "truth: 189000, predict.: 192305.4437893863, score: 0.017337855027554028\n",
      "truth: 438780, predict.: 426690.03737582004, score: 0.02794024209085144\n",
      "truth: 87000, predict.: 97283.92968892555, score: 0.11172447934873553\n",
      "truth: 130500, predict.: 122936.62536723213, score: 0.05970377365591695\n",
      "truth: 392000, predict.: 238468.46138642536, score: 0.4970231331789794\n",
      "truth: 55993, predict.: 95430.83829462984, score: 0.5331677153839358\n",
      "truth: 285000, predict.: 313441.34681866533, score: 0.09512275243171331\n",
      "truth: 175000, predict.: 173849.2145231016, score: 0.0065975957846511335\n",
      "truth: 271000, predict.: 289660.9411986676, score: 0.0665920120860708\n",
      "truth: 230500, predict.: 256649.5497727656, score: 0.10746023029284402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth: 177000, predict.: 180594.30448243636, score: 0.020103258825965753\n",
      "truth: 164700, predict.: 159773.29441113956, score: 0.030369549424559494\n",
      "truth: 143000, predict.: 142500.51052256956, score: 0.003499023431542625\n",
      "truth: 113000, predict.: 112592.25741878276, score: 0.0036148351459051042\n",
      "truth: 129500, predict.: 125782.27946842657, score: 0.029128181290468902\n",
      "truth: 275000, predict.: 270429.8964837677, score: 0.016758134238097355\n",
      "truth: 179400, predict.: 165648.99261154313, score: 0.07974643960208283\n",
      "truth: 94750, predict.: 124318.44516299381, score: 0.27160202563819524\n",
      "truth: 170000, predict.: 172910.0437379324, score: 0.016972944820091485\n",
      "truth: 111250, predict.: 126354.65123242677, score: 0.12731164987386023\n",
      "truth: 144000, predict.: 154196.01706849405, score: 0.06841087238349353\n",
      "truth: 87000, predict.: 109579.86626234732, score: 0.23074316853373134\n",
      "truth: 166000, predict.: 122618.23214693775, score: 0.302909932173856\n",
      "truth: 106000, predict.: 97819.99924799844, score: 0.08030925780009035\n",
      "truth: 112000, predict.: 111253.03902482656, score: 0.006691573598217815\n",
      "truth: 295493, predict.: 265171.2911204312, score: 0.10826876217313419\n",
      "truth: 179500, predict.: 178799.89004533147, score: 0.003907938334265282\n",
      "truth: 81000, predict.: 83289.67116135493, score: 0.02787505176602245\n",
      "truth: 185000, predict.: 171758.79974215056, score: 0.07426424281595878\n",
      "truth: 113000, predict.: 110050.44826545757, score: 0.026448700277061477\n",
      "truth: 125500, predict.: 128887.9945797618, score: 0.026637800111664944\n",
      "truth: 244000, predict.: 280553.54601756687, score: 0.13959584236808098\n",
      "truth: 139000, predict.: 123706.94581749721, score: 0.11655761543432241\n",
      "truth: 137500, predict.: 163756.54842805746, score: 0.1747557809160405\n",
      "truth: 119500, predict.: 106387.81554955569, score: 0.11622428517048\n",
      "truth: 127000, predict.: 139511.70253868328, score: 0.09396069429755727\n",
      "truth: 210000, predict.: 199977.43989976574, score: 0.04890273237491982\n",
      "truth: 263000, predict.: 233896.60324947955, score: 0.11727440781688259\n",
      "truth: 158000, predict.: 164088.3982319713, score: 0.03781002835476954\n",
      "truth: 176432, predict.: 174869.76457788894, score: 0.00889398792582341\n",
      "truth: 80000, predict.: 79582.00803853903, score: 0.005238531385236556\n",
      "truth: 140000, predict.: 138527.16167277616, score: 0.010575927105527683\n",
      "truth: 274725, predict.: 245872.04813957485, score: 0.11095889907801393\n",
      "truth: 135000, predict.: 143539.8038563509, score: 0.0613371563932219\n",
      "truth: 197000, predict.: 243927.83694551117, score: 0.2136677260246298\n",
      "truth: 172500, predict.: 201197.75118942844, score: 0.15389019783827607\n",
      "truth: 176500, predict.: 174875.81395209362, score: 0.00924473629812006\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.1, max_depth=4, min_samples_leaf=2)\n",
    "gbr.fit(X_train, y_train)\n",
    "prediction = gbr.predict(X_test)\n",
    "\n",
    "for t,p in zip(y_test, prediction):\n",
    "    print(\"truth: {}, predict.: {}, score: {}\".format(t, p, sqrt(mean_squared_log_error([t], [p]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the score is quite close to 0 for most records, however it is very high for others. Let's visualize the performance per record on original features vs SalePrice plots.\n",
    "Each dot represents a record, the color of the dot indicates the score, the darker the dot the worse the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=../reports/figures/score-gbr.pdf width=700 height=350></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = read_raw_data(\"../data/raw/train.csv\")\n",
    "result = pd.DataFrame(X_test)\n",
    "result = result[['Id']]\n",
    "result = pd.merge(result, original, on='Id', how='inner')\n",
    "result['Prediction'] = prediction\n",
    "\n",
    "def msle(row):\n",
    "    return sqrt(mean_squared_log_error([row['SalePrice']], [row['Prediction']]))\n",
    "\n",
    "result['Score'] = result.apply(msle, axis=1)\n",
    "result.to_csv(\"results.csv\")\n",
    "from IPython.display import HTML\n",
    "HTML('<iframe src=../reports/figures/score-gbr.pdf width=700 height=350></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main observation is that the worst predictions seem to preliminarily concern either low-price houses or outliers. We see that\n",
    "- MSSubClass : many bad scores obtained for classes 20 and 30 (category not included in those retained with RFECV)\n",
    "- OverallQual : bad quality --> bad score (bad quality --> lower SalePrice)\n",
    "- GarageArea : no garage --> bad score\n",
    "\n",
    "Let's confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 34900  84900 134900 184900 234900 284900 334900 384900 434900 484900\n",
      " 534900 584900 634900 684900 734900]\n",
      "relative frequency of bad predictions per SalePrice: \n",
      "1     0.857143\n",
      "2     0.287129\n",
      "3     0.216667\n",
      "4     0.215385\n",
      "5     0.473684\n",
      "6     0.307692\n",
      "7     0.666667\n",
      "8     0.333333\n",
      "9     1.000000\n",
      "15    1.000000\n",
      "Name: BinPrice, dtype: float64\n",
      "relative frequency of bad predictions per SalePrice, weighted by relative frequency of SalePrice: \n",
      "1     0.032877\n",
      "2     0.079452\n",
      "3     0.071233\n",
      "4     0.038356\n",
      "5     0.049315\n",
      "6     0.010959\n",
      "7     0.010959\n",
      "8     0.005479\n",
      "9     0.002740\n",
      "15    0.002740\n",
      "Name: BinPrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "bins = np.arange(np.amin(result['SalePrice']), np.amax(result['SalePrice']), step=50000)\n",
    "print(bins)\n",
    "result['BinPrice'] = np.digitize(result['SalePrice'], bins)\n",
    "\n",
    "freq_score = result[(result['Score'] >= 0.1)]['BinPrice'].value_counts()/result['BinPrice'].value_counts()\n",
    "freq_price = result['BinPrice'].value_counts()/len(result)\n",
    "print(\"relative frequency of bad predictions per SalePrice: \\n{}\".format(freq_score))\n",
    "print(\"relative frequency of bad predictions per SalePrice, weighted by relative frequency of SalePrice: \\n{}\"\n",
    "      .format(freq_score*freq_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for houses with a price between 39.300 and 89.300 the majority of predictions that are made are bad, The same holds for houses lying in the price range 239.300 - 289.300. If we weigh this with the relative frequency of the price ranges, we see that it is for houses in the price range 89.300 - 139.300 for which most bad predictions are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20     0.084932\n",
       "30     0.013699\n",
       "40     0.002740\n",
       "45     0.002740\n",
       "50     0.041096\n",
       "60     0.054795\n",
       "70     0.016438\n",
       "75     0.008219\n",
       "80     0.019178\n",
       "85          NaN\n",
       "90     0.016438\n",
       "120    0.016438\n",
       "160    0.016438\n",
       "180    0.002740\n",
       "190    0.008219\n",
       "Name: MSSubClass, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relative frequency of bad scores per MSSubClass category, weighted by relative frequency of that category\n",
    "(result[(result['Score'] >= 0.1)]['MSSubClass'].value_counts()/result['MSSubClass'].value_counts())*(result['MSSubClass'].value_counts()/len(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance for class 20 is worse than for other classes, however it it worse for classes 50 and 60 than for 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relative frequency of bad predictions per overall quality: \n",
      "2     1.000000\n",
      "3     0.166667\n",
      "4     0.472222\n",
      "5     0.230769\n",
      "6     0.237113\n",
      "7     0.362500\n",
      "8     0.295455\n",
      "9     0.428571\n",
      "10    1.000000\n",
      "Name: OverallQual, dtype: float64\n",
      "relative frequency of bad predictions per overall quality, weighted by relative frequency of quality rating: \n",
      "2     0.002740\n",
      "3     0.002740\n",
      "4     0.046575\n",
      "5     0.057534\n",
      "6     0.063014\n",
      "7     0.079452\n",
      "8     0.035616\n",
      "9     0.008219\n",
      "10    0.008219\n",
      "Name: OverallQual, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "freq_score = result[(result['Score'] >= 0.1)]['OverallQual'].value_counts()/result['OverallQual'].value_counts()\n",
    "freq_price = result['OverallQual'].value_counts()/len(result)\n",
    "print(\"relative frequency of bad predictions per overall quality: \\n{}\".format(freq_score))\n",
    "print(\"relative frequency of bad predictions per overall quality, weighted by relative frequency of quality rating: \\n{}\"\n",
    "      .format(freq_score*freq_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bad scores are obtained for houses with a quality ranking of 1, 10 and 3. It is however the houses in classes 6 and 5 for which most predictions are made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how other models perform on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score-gbr: 0.21277160901718162, score-lasso: 0.0871720136012204\n",
      "score-gbr: 0.15407156782438847, score-lasso: 0.28730848853702007\n",
      "score-gbr: 0.2589232896086848, score-lasso: 0.08178458303863678\n",
      "score-gbr: 0.34148458679466565, score-lasso: 0.5743351878905898\n",
      "score-gbr: 0.1176018483174186, score-lasso: 0.07605277216723749\n",
      "score-gbr: 0.20333510457363246, score-lasso: 0.12816572767591516\n",
      "score-gbr: 0.11550920885772342, score-lasso: 0.19517526037136435\n",
      "score-gbr: 0.2363493105266734, score-lasso: 0.17994923966578646\n",
      "score-gbr: 0.12474962284233371, score-lasso: 0.05696186319185159\n",
      "score-gbr: 0.11655547993473725, score-lasso: 0.04259919484794139\n",
      "score-gbr: 0.10998271733197917, score-lasso: 0.4587709439794647\n",
      "score-gbr: 0.1256339554008985, score-lasso: 0.17762910413095767\n",
      "score-gbr: 0.14657613665691116, score-lasso: 0.00016118876914461566\n",
      "score-gbr: 0.15548728175247994, score-lasso: 0.1280962145618112\n",
      "score-gbr: 0.23028527533670662, score-lasso: 0.3095977704121182\n",
      "score-gbr: 0.21849267936937267, score-lasso: 0.6112676134035961\n",
      "score-gbr: 0.10755820607515254, score-lasso: 0.023536553739736732\n",
      "score-gbr: 0.1053956576246815, score-lasso: 0.1235542890278456\n",
      "score-gbr: 0.21253475168243163, score-lasso: 0.18373550404310102\n",
      "score-gbr: 0.1587095715588589, score-lasso: 0.23519346280206754\n",
      "score-gbr: 0.10215755107313917, score-lasso: 0.11968026210461602\n",
      "score-gbr: 0.16716582424221116, score-lasso: 0.15795736861592502\n",
      "score-gbr: 0.10140610269040451, score-lasso: 0.17394786742783452\n",
      "score-gbr: 0.12968070459411507, score-lasso: 0.10518001422174272\n",
      "score-gbr: 0.13932143157913934, score-lasso: 0.11954905866422116\n",
      "score-gbr: 0.5340011488883025, score-lasso: 0.00707373088851071\n",
      "score-gbr: 0.5185143781847916, score-lasso: 0.5284290845281898\n",
      "score-gbr: 0.13794421386907274, score-lasso: 0.14202888943596825\n",
      "score-gbr: 0.8422117257626596, score-lasso: 1.6796660594482802\n",
      "score-gbr: 0.4008260706322968, score-lasso: 0.36006301864907186\n",
      "score-gbr: 0.20382584578058172, score-lasso: 0.3179988406641616\n",
      "score-gbr: 0.14987299168397072, score-lasso: 0.16133490798807415\n",
      "score-gbr: 0.14824616069546082, score-lasso: 0.11411967040232085\n",
      "score-gbr: 0.15000163392895516, score-lasso: 0.3856726320496673\n",
      "score-gbr: 0.2177925876449862, score-lasso: 0.38882713685998915\n",
      "score-gbr: 0.12712561970309721, score-lasso: 0.1392406810363802\n",
      "score-gbr: 0.22907408934604234, score-lasso: 0.27097429176333065\n",
      "score-gbr: 0.32897302261108585, score-lasso: 0.15205355827991696\n",
      "score-gbr: 0.2056741816179226, score-lasso: 0.17038575633175768\n",
      "score-gbr: 0.25609615327686264, score-lasso: 0.4142456182013685\n",
      "score-gbr: 0.14214794061452452, score-lasso: 0.15160337727193784\n",
      "score-gbr: 0.104842810529016, score-lasso: 0.23142116702178583\n",
      "score-gbr: 0.13672048608943044, score-lasso: 0.19035005616494693\n",
      "score-gbr: 0.2058600622995872, score-lasso: 0.09598621388894024\n",
      "score-gbr: 0.1507802343756257, score-lasso: 0.11139131874394259\n",
      "score-gbr: 0.11334198917268701, score-lasso: 0.11447822656174544\n",
      "score-gbr: 0.13317297054223332, score-lasso: 0.032136620915608205\n",
      "score-gbr: 0.17798660224107365, score-lasso: 0.35745051153270424\n",
      "score-gbr: 0.12581935230536168, score-lasso: 0.18043969783909297\n",
      "score-gbr: 0.21798173177227298, score-lasso: 0.31001753277395494\n",
      "score-gbr: 0.1124741868879191, score-lasso: 0.1037096965929063\n",
      "score-gbr: 0.10173123403871642, score-lasso: 0.1371947207302675\n",
      "score-gbr: 0.10804301539044658, score-lasso: 0.14406196026610196\n",
      "score-gbr: 0.136134918551452, score-lasso: 0.08644783217210161\n",
      "score-gbr: 0.11294248841892163, score-lasso: 0.051272482434011835\n",
      "score-gbr: 0.14727227572200263, score-lasso: 0.00612084608761343\n",
      "score-gbr: 0.17241000880135182, score-lasso: 0.025100696227728037\n",
      "score-gbr: 0.1455041047980199, score-lasso: 0.3700911102633455\n",
      "score-gbr: 0.11575800151849869, score-lasso: 0.24426802431065298\n",
      "score-gbr: 0.11407276588637494, score-lasso: 0.030699025374657296\n",
      "score-gbr: 0.28376663479367537, score-lasso: 0.5707465605303135\n",
      "score-gbr: 0.297580250756603, score-lasso: 0.4102857831013189\n",
      "score-gbr: 0.2627582172199787, score-lasso: 0.5860261010935748\n",
      "score-gbr: 0.16114849696990596, score-lasso: 0.22744739759319899\n",
      "score-gbr: 0.13959129273317572, score-lasso: 0.29623651649692384\n",
      "score-gbr: 0.3315716008642777, score-lasso: 0.38949504573661287\n",
      "score-gbr: 0.1315049391865557, score-lasso: 0.01871839052587454\n",
      "score-gbr: 0.14125439639542314, score-lasso: 0.13759786588098954\n",
      "score-gbr: 0.10442645955180829, score-lasso: 0.04277411181126922\n",
      "score-gbr: 0.11071749920042429, score-lasso: 0.07155422275985579\n",
      "score-gbr: 0.41741065348424655, score-lasso: 0.6218766978232537\n",
      "score-gbr: 0.18592765367826303, score-lasso: 0.13979718085569282\n",
      "score-gbr: 0.18634368883472163, score-lasso: 0.09617321672067902\n",
      "score-gbr: 0.15125012929712867, score-lasso: 0.04157585674895081\n",
      "score-gbr: 0.16349129002080254, score-lasso: 0.1828363340509611\n",
      "score-gbr: 0.2424907733696351, score-lasso: 0.02101000472122294\n",
      "score-gbr: 0.16158456617234762, score-lasso: 0.11518262924174749\n",
      "score-gbr: 0.12177880169096866, score-lasso: 0.05269902451478892\n",
      "score-gbr: 0.14271022005986111, score-lasso: 0.10184597062535872\n",
      "score-gbr: 0.17999137390514086, score-lasso: 0.16345623510262008\n",
      "score-gbr: 0.1684481608624715, score-lasso: 0.2127559730768258\n",
      "score-gbr: 0.13015373359041682, score-lasso: 0.13443489516311757\n",
      "score-gbr: 0.29574929962712737, score-lasso: 0.3578619273330492\n",
      "score-gbr: 0.18038385691338732, score-lasso: 0.23899654741504683\n",
      "score-gbr: 0.12461409981832716, score-lasso: 0.09280820235826504\n",
      "score-gbr: 0.22034120321882256, score-lasso: 0.16313039633232052\n",
      "score-gbr: 0.21124336927377385, score-lasso: 0.16878280677072333\n",
      "score-gbr: 0.23189329689933658, score-lasso: 0.25377433645873104\n",
      "score-gbr: 0.12289948176123033, score-lasso: 0.1331600237888857\n",
      "score-gbr: 0.21328034959169884, score-lasso: 0.3064406997106044\n",
      "score-gbr: 0.5789324025574505, score-lasso: 0.41155851199195403\n",
      "score-gbr: 0.3351109583010867, score-lasso: 0.27323000863285074\n",
      "score-gbr: 0.13454313306063703, score-lasso: 0.21766927938629443\n",
      "score-gbr: 0.23386153388558917, score-lasso: 0.10914627867851401\n",
      "score-gbr: 0.10951602404515803, score-lasso: 0.009637981112337712\n",
      "score-gbr: 0.15673767699197505, score-lasso: 0.09278412726626506\n",
      "score-gbr: 0.11133601615104638, score-lasso: 0.052341117927271696\n",
      "score-gbr: 0.16077764856586718, score-lasso: 0.01459402414675992\n",
      "score-gbr: 0.11663815786391218, score-lasso: 0.19607168071417114\n",
      "score-gbr: 0.13626901991619, score-lasso: 0.07700841629720045\n",
      "score-gbr: 0.11172447934873553, score-lasso: 0.09610347113867768\n",
      "score-gbr: 0.4970231331789794, score-lasso: 0.6764999897843893\n",
      "score-gbr: 0.5331677153839358, score-lasso: 0.7382012774497806\n",
      "score-gbr: 0.10746023029284402, score-lasso: 0.027675094220972696\n",
      "score-gbr: 0.27160202563819524, score-lasso: 0.3161907752806119\n",
      "score-gbr: 0.12731164987386023, score-lasso: 0.1977680009794316\n",
      "score-gbr: 0.23074316853373134, score-lasso: 0.2711626171383372\n",
      "score-gbr: 0.302909932173856, score-lasso: 0.0960619070810047\n",
      "score-gbr: 0.10826876217313419, score-lasso: 0.19972928182887273\n",
      "score-gbr: 0.13959584236808098, score-lasso: 0.18067643952054802\n",
      "score-gbr: 0.11655761543432241, score-lasso: 0.05084379605598954\n",
      "score-gbr: 0.1747557809160405, score-lasso: 0.10990448743152115\n",
      "score-gbr: 0.11622428517048, score-lasso: 0.12542264980382534\n",
      "score-gbr: 0.11727440781688259, score-lasso: 0.13615013532433018\n",
      "score-gbr: 0.11095889907801393, score-lasso: 0.26560339304577774\n",
      "score-gbr: 0.2136677260246298, score-lasso: 0.26603076979210627\n",
      "score-gbr: 0.15389019783827607, score-lasso: 0.013484573336475236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "y_train_log = np.log1p(y_train)\n",
    "y_test_log = np.log1p(y_test)\n",
    "\n",
    "lasso = Lasso(max_iter=50000)\n",
    "lasso.fit(X_train, y_train_log)\n",
    "lasso_predict = lasso.predict(X_test)\n",
    "\n",
    "for t,tl,p,l in zip(y_test, y_test_log, prediction, lasso_predict):\n",
    "    score_gbr = sqrt(mean_squared_log_error([t], [p]))\n",
    "    if(score_gbr > 0.1):\n",
    "        print(\"score-gbr: {}, score-lasso: {}\".format(score_gbr, sqrt(mean_squared_error([tl], [l]))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for some of the houses for which the GBR produced a bad score the prediction is improved by Lasso. Let's try combining Lasso and GBR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10025812686173259\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "avg_score = 0\n",
    "for t, gbrp, lp in zip(y_test, prediction, lasso_predict):\n",
    "    mean_pred = (np.expm1(lp) + gbrp)/2.0\n",
    "    score = sqrt(mean_squared_log_error([t], [mean_pred]))\n",
    "    avg_score += score\n",
    "avg_score = avg_score/float(len(lasso_predict))\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Combining both models actually allows to improve the overall score. The best combination on the Kaggle test set is 20% Lasso and 80% GBR : using the features selected previously and this averaging of models we get a score of 0.12916."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's, for fun, see what happens if we add an SVM on top. SVMs are known to be sensitive to the scaling of the data, so we should apply a scaler, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09262488260582817\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "\n",
    "svr_rbf = SVR(kernel='linear', C=1000)\n",
    "svr_rbf.fit(X_train_minmax, y_train_log)\n",
    "svr_pred = svr_rbf.predict(X_test_minmax)\n",
    "\n",
    "for t, lp, gbrp, svr in zip(y_test, lasso_predict, prediction, svr_pred):\n",
    "#    print(\"gbr: {:.3f}, lasso: {:.3f}, svr: {:.3f}, real: {}\".format(gbrp, np.expm1(lp), np.expm1(svr), t))\n",
    "    mean_pred = (np.expm1(lp) + gbrp + np.expm1(svr))/3.0\n",
    "    score = sqrt(mean_squared_log_error([t], [mean_pred]))\n",
    "    avg_score += score\n",
    "avg_score = avg_score/float(len(X_test))\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the SVR actually improves the score on the test set. Since we saw that the GBR performs rather bad on the more extreme feature values, using KNeighbors should allow to mitigate this. Let's see what happens when we replace the SVR with KNeighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11856610534011609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knb = KNeighborsRegressor(n_neighbors=5)\n",
    "knb.fit(X_train, y_train)\n",
    "nn_predict = knb.predict(X_test)\n",
    "\n",
    "for t, gbrp, lp, n in zip(y_test, prediction, lasso_predict, nn_predict):\n",
    "    mean_pred = (np.expm1(lp) + gbrp + n)/3.0\n",
    "    score = sqrt(mean_squared_log_error([t], [mean_pred]))\n",
    "#    print(\"gbr: {:.3f}, lasso: {:.3f}, nn: {:.3f}, mean: {:.3f}, real: {}, score: {}\".format(gbrp, np.expm1(lp), n, mean_pred, t, score))\n",
    "    avg_score += score\n",
    "avg_score = avg_score/float(len(nn_predict))\n",
    "print(avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighbors does not improve the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have seen that we can improve the quality of the prediction on the test set by combining several models, let's build a transformer combining the 4 models and let a LinearRegression determine the final prediction. While it would be interesting to do a GridSearch to set the parameters of the 4 models this will be too time-consuming at this stage. Let's just run a GridSearch to determine which of the 4 models should actually be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%aimport models.Stacking_Transformer\n",
    "import models.Stacking_Transformer as st\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "# Check we have an estimator adhereing to the scikit-learn interface and standards\n",
    "check_estimator(st.StackingTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False, score=-0.015076082546312129, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False, score=-0.0254929031957322, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False, score=-0.016616802178356857, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.8s remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False, score=-0.01928511068451359, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    1.1s remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=False, score=-0.020161174124038613, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    1.5s remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True, score=-0.015272577019214802, total=  25.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   26.5s remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True, score=-0.021984851213633177, total=  25.6s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   52.1s remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True, score=-0.015929423638780412, total=  30.7s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.4min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True, score=-0.0194519603234641, total=  29.8s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=False, transform__dosvr=True, score=-0.020156885227469137, total=  25.8s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False, score=-0.015190185512926791, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  11 out of  11 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False, score=-0.021825900210758444, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False, score=-0.015790239181139122, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  13 out of  13 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False, score=-0.01958990749908148, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  14 out of  14 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=False, score=-0.020190263938357475, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  2.3min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True, score=-0.015201622410005507, total=  27.1s\n",
      "[Parallel(n_jobs=1)]: Done  16 out of  16 | elapsed:  2.8min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True, score=-0.021355318846109618, total=  25.0s\n",
      "[Parallel(n_jobs=1)]: Done  17 out of  17 | elapsed:  3.2min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True, score=-0.015424986465240952, total=  27.2s\n",
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:  3.7min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True, score=-0.019499014853747658, total=  28.9s\n",
      "[Parallel(n_jobs=1)]: Done  19 out of  19 | elapsed:  4.1min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=False, transform__dolasso=True, transform__dosvr=True, score=-0.019985894326397094, total=  24.1s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:  4.5min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False, score=-0.014989564852715262, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed:  4.5min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False, score=-0.025792736344604713, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  22 out of  22 | elapsed:  4.5min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False, score=-0.016134236079439934, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  23 out of  23 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False, score=-0.019450200579544788, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=False, score=-0.02027614128794752, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  4.6min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True, score=-0.015188291460591408, total=  25.2s\n",
      "[Parallel(n_jobs=1)]: Done  26 out of  26 | elapsed:  5.0min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True, score=-0.023082400582199614, total=  25.3s\n",
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:  5.4min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True, score=-0.015703491997878957, total=  26.9s\n",
      "[Parallel(n_jobs=1)]: Done  28 out of  28 | elapsed:  5.9min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True, score=-0.019555851293306697, total=  28.7s\n",
      "[Parallel(n_jobs=1)]: Done  29 out of  29 | elapsed:  6.3min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=False, transform__dosvr=True, score=-0.020235206899276846, total=  25.1s\n",
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False, score=-0.01520836879979594, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  31 out of  31 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False, score=-0.022741770904943052, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False, score=-0.015261541064807323, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  33 out of  33 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False, score=-0.019903006538476303, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  34 out of  34 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=False, score=-0.02036052145445005, total=   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  35 out of  35 | elapsed:  6.8min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True, score=-0.014975784130605636, total=  25.3s\n",
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  7.2min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True, score=-0.02264215903207271, total=  23.8s\n",
      "[Parallel(n_jobs=1)]: Done  37 out of  37 | elapsed:  7.6min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True, score=-0.016124367377579038, total=  26.6s\n",
      "[Parallel(n_jobs=1)]: Done  38 out of  38 | elapsed:  8.1min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True, score=-0.01965739149295894, total=  28.8s\n",
      "[Parallel(n_jobs=1)]: Done  39 out of  39 | elapsed:  8.5min remaining:    0.0s\n",
      "[CV] transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True \n",
      "[CV]  transform__dogbr=True, transform__doknn=True, transform__dolasso=True, transform__dosvr=True, score=-0.020145329814650496, total=  24.0s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  8.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  8.9min finished\n",
      "Best cross_validaton score : 0.135\n",
      "Test set score : 0.135\n",
      "Best parameters : {'transform__dogbr': True, 'transform__doknn': False, 'transform__dolasso': True, 'transform__dosvr': True}\n"
     ]
    }
   ],
   "source": [
    "%aimport models.Stacking_Transformer\n",
    "import models.Stacking_Transformer as st\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn. model_selection import GridSearchCV\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "\n",
    "param_grid = {\"transform__dogbr\": [True],\n",
    "              \"transform__dolasso\": [False, True],\n",
    "              \"transform__dosvr\" : [False, True],\n",
    "              \"transform__doknn\" : [False, True]\n",
    "             }\n",
    "\n",
    "pipe = Pipeline([(\"transform\", st.StackingTransformer()), (\"lr\", LinearRegression())])\n",
    "gridcv = GridSearchCV(pipe, cv=5, scoring='neg_mean_squared_log_error', param_grid=param_grid, verbose=100)\n",
    "gridcv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best cross_validaton score : {:.3f}\".format(sqrt(abs(gridcv.best_score_))))\n",
    "print(\"Test set score : {:.3f}\".format(sqrt(abs(gridcv.score(X_test, y_test)))))\n",
    "print(\"Best parameters : {}\".format(gridcv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further attempts at improving the model could be made by :\n",
    "\n",
    "- feature engineering : PCA + polynomials\n",
    "- grid searching over the models to use\n",
    "- possibly integrating original features in the transformer result and doing a GBR over them - the GBR could learn in which cases which model performs better\n",
    "- using XGBoost library for the GradientBoosting -> should allow to increment the number of estimators without increasing running time (danger: overfitting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
